* History of DevOps

Before DevOps, We had two approaches for software development namely the Waterfall and the Agile.
** Waterfall Model
*** Top-down approch
**** Introduction
https://d1jnx9ba8s6j9r.cloudfront.net/blog/wp-content/uploads/2019/06/Waterfall-Phases-403x300.png
The waterfall model is a software development model that is pretty straight forward and linear. This model follows a top-down approach.
**** > Requirement Gathering and Analysis[Client + Developers]
This model starting with *Requirements gathering and analysis*. In this phase we  get the requirements from the client for developing an application. After this, you try to analyze these requirements.And make a blueprint of software
**** > Design[Developers +..  ]
The next phase is the Design phase where you prepare a blueprint of the software. Here, you think about how the software is actually going to look like.

**** > Implementation[Developers]
Once the design is ready, you move further to Implementation phase where you begin with the coding for the application. The team of developers works together on various components of the application.
**** > Testing[Testers]
Once you complete the application development, you test it in the *Verification phase*. There are various tests conducted on the application such as unit testing, integration testing, performance testing, etc.
**** > Depolyment [Developers + Testers]
After all the tests on the application are completed, it is *deployed* onto the production servers.
**** > maintenance phase[Operator]
At last, comes the *Maintenance phase*. In this phase, the application is monitored for performance. Any issues related to the performance of the application are resolved in this phase.

*** Advantages of the Waterfall Model:
- Simple to understand and use
- Allows for easy testing and analysis
- Saves a significant amount of time and money
- Good for small projects if all requirements are clearly defined
- Allows for departmentalization & managerial control
*** Disadvantages of Waterfall Model:
- Risky and uncertain
- Lack of visibility of the current progress
- Not suitable when the requirements keep changing
- Difficult to make changes to the product when it is in the testing phase
- The end product is available only at the end of the cycle
- Not suitable for large and complex projects

** Agile Methodology
https://www.hashminds.com/wp-content/uploads/2018/01/agile3-e1516054093712.jpg
Agile Methodology is a people-focused, results-focused approach to software development that respects our rapidly changing world.
It’s centered around adaptive planning, self-organization, and short delivery times. It’s flexible, fast, and aims for continuous improvements in quality
Agile Methodology is an iterative based software development approach where the software project is broken down into various iterations or sprints.
Each iteration has phases like the waterfall model such as Requirements Gathering, Design, Development, Testing, and Maintenance.
The duration of each iteration is generally (2-8)(1-4) weeks or (1-2 months).

*** Agile Methodology Overview

- It abandons the risk of spending months or years on a process that ultimately fails because of some small mistake in an early phase.It relies instead on trusting employees and teams to work directly with customers to understand the goals and provide solutions in a fast and incremental way.
  - Faster, smaller. Traditional software development relied on phases like outlining the requirements, planning, design, building, testing, and delivery.
    Agile methodology, by contrast, looks to deploy the first increment in a couple weeks and the entire piece of software in a couple months.
  - Communication. Agile teams within the business work together daily at every stage of the project through face-to-face meetings. This collaboration and communication ensure the process stays on track even as conditions change.
  - Feedback. Rather than waiting until the delivery phase to gauge success, teams leveraging Agile methodology track the success and speed of the development process regularly. Velocity is measured after the delivery of each increment.
  - Trust. Agile teams and employees are self-organizing. Rather than following a manifesto of rules from management intended to produce the desired result, they understand the goals and create their own path to reach them.
  - Adjust. Participants tune and adjust the process continually, following the KIS or Keep It Simple principle.
*** model Agile Process
- In Agile, a company releases the application with some high priority features in the first iteration.
- After its release, the end-users or the customers give you feedback about the performance of the application.
- Then you make the necessary changes into the application along with some new features and the application is again released which is the second iteration.
- You repeat this entire procedure until you achieve the desired software quality.
  Benefits of Agile Methodology


**** Advantages of Agile Model
- It adaptively responds to requirement changes favorably
- Fixing errors early in the development process makes this process more cost-effective
- Improves the quality of the product and makes it highly error-free
- Allows for direct communication between people involved in software project
- Highly suitable for large & long-term projects
- Minimum resource requirements & very easy to manage
The benefits of Agile are tied directly to its faster, lighter, more engaged mindset. The process, in a nutshell, delivers what the customer wants, when the customer wants it. There’s much less wasted time spent developing in the wrong direction, and the entire system is quicker to respond to changes. For a more comprehensive list of benefits, see this post.
- Faster. Speed is one of the biggest benefits of Agile Methodology. A faster software development life cycle means less time between paying and getting paid. That, in turn, means a more profitable business.
- Increased customer satisfaction. With Agile, customers don’t wait for months or years, only to get exactly what they didn’t want. Instead, they get iterations of something very close to what they want, very fast. The system adjusts quickly to refine the successful customer solution, adapting as it goes to changes in the overall environment.
- Values employees. Employees whose ideas are valued are vastly more productive than those who are ordered to follow a set of rules. The Agile Methodology respects employees by giving them the goal, then trusting them to reach it. Since they’re the ones with their hands on the controls and the ones who see the obstacles that crop up every day, employees are in the best position to respond to challenges and meet the goals at hand.
- Eliminates rework. By involving the customer at more than just the phases of requirements and delivery, the project remains on-task and in-tune with customer needs at every step. This means less backtracking and less “out on a limb” time between the time we do the work and the time the customer suggests revisions.
**** Disadvantages of Agile Model
- Highly dependent on clear customer requirements
- Quite Difficult to predict time and effort for larger projects
- Not suitable for complex projects
- Lacks documentation efficiency
- Increased maintainability risks
**** The advantages of the Agile Model are as follows −
- Is a very realistic approach to software development.
- Promotes teamwork and cross training.
- Functionality can be developed rapidly and demonstrated.
- Resource requirements are minimum.
- Suitable for fixed or changing requirements
- Delivers early partial working solutions.
- Good model for environments that change steadily.
- Minimal rules, documentation easily employed.
- Enables concurrent development and delivery within an overall planned context.
- Little or no planning required.
- Easy to manage.
- Gives flexibility to developers.

**** The disadvantages of the Agile Model are as follows −
- Not suitable for handling complex dependencies.
- More risk of sustainability, maintainability and extensibility.
- An overall plan, an agile leader and agile PM practice is a must without which it will not work.
- Strict delivery management dictates the scope, functionality to be delivered, and adjustments to meet the deadlines.
- Depends heavily on customer interaction, so if customer is not clear, team can be driven in the wrong direction.
- There is a very high individual dependency, since there is minimum documentation generated.
- Transfer of technology to new team members may be quite challenging due to lack of documentation.
  
*** Diagram 
agile.png
Real time there are 5 environment
- dev env
- sit env or (SIT:System Integration Test or, QA) 
- uat env or (UAT: User Acceptanec Test)
- pre production : 
- production :
(development, sit (System Integration and Testing),uat (User Acceptance Testing),prod)
** DevOps
https://www.ibm.com/cloud/learn/devops-a-complete-guide
DevOps is a set of practices that combines software development (Dev) and IT operations (Ops).It aims to shorten the systems development life cycle and provide continuous delivery with high software quality.
DevOps is complementary with Agile software development; several DevOps aspects came from the Agile methodology. 

By definition, DevOps outlines a software development process and an organizational culture shift that speeds the delivery of higher quality software by automating and integrating the efforts of development and IT operations teams – two groups that traditionally practiced separately from each other, or in silos.
*** Stages and Tools
source : good explaination  https://dzone.com/articles/how-to-orc0hestrate-devops-tools-together-to-solve
As mentioned earlier, the various stages such as 
 - continuous development, 
 - continuous testing,
 - continuous integration, 
 - continuous deployment, and 
 - continuous monitoring 
constitute the DevOps Life cycle [[img] [https://d1jnx9ba8s6j9r.cloudfront.net/blog/wp-content/uploads/2017/10/devops-explanation.png]]. Now let us have a look at each of the stages of DevOps life cycle one by one.


*** Stage – 1: Continuous Development [ Planning(Requirement Gathering & Analysis + Design) + Coding]
- Tools Used: Git, SVN, Mercurial, CVS and JIRA
- Process Flow: https://i.stack.imgur.com/UvZ0M.png
- This is the phase that involves ‘planning‘ and ‘coding‘ of the software.
  You decide the project vision during the planning phase and the developers begin developing the code for the application.
- There are no DevOps tools that are required for planning, but there are a number of tools for maintaining the code.
- The code can be in any language, but you maintain it by using Version Control tools. This process of maintaining the code is known as Source Code Management.
- After the code is developed, then you move to the Continuous Integration phase.

*** Stage – 2: Continuous Integration
- Tools: Jenkins, TeamCity, Travis 
- Process Flow:
- This stage is the core of the entire DevOps life cycle. It is a practice in which the developers require to commit changes to the source code more frequently. This may be either on a daily or weekly basis.
- You then build every commit and this allows early detection of problems if they are present. Building code not only involves compilation but it also includes code review, unit testing, integration testing, and packaging.
- The code supporting new functionality is continuously integrated with the existing code. Since there is a continuous development of software, you need to integrate the updated code continuously as well as smoothly with the systems to reflect changes to the end-users.
- In this stage, you use the tools for building/ packaging the code into an executable file so that you can forward it to the next phases.

*** Stage – 3: Continuous Testing [Build Code + Testing (Test performacne + Test functional + SIT + UAT + Preproduction + Production )]

- Tools: Jenkins, Selenium TestNG, JUnit
- Process Flow:
- This is the stage where you test the developed software continuously for bugs using automation testing tools. These tools allow QAs to test multiple code-bases thoroughly in parallel to ensure that there are no flaws in the functionality. In this phase, you can use Docker Containers for simulating the test environment.
- Selenium is used for automation testing, and the reports are generated by TestNG. You can automate this entire testing phase with the help of a Continuous Integration tool called Jenkins.
- Suppose you have written a selenium code in Java to test your application. Now you can build this code using ant or maven. Once you build the code, you then test it for User Acceptance Testing (UAT). This entire process can be automated using Jenkins.

*** Stage – 4: Continuous Deployment

Tools Used: 
*** Stage – 5: Contionous monitoring 
* AWS EC2 installation
* Linux and Shell
Visit : Linux Tutorial for both Linux and Shell

What is different btw normal user and root user

#+BEGIN_SRC sh
 sudo su -
 ls -latr
 
#+END_SRC

* Vi Editor Tutorial
Visit : vim tutorial
* git
** What is git
- git is free and opensouce VCS (Version Control System) created by linux torvaldss in 2005. Version Control System  mean which is used to track all change in project
- Using git
  -  No data is lost and undo previous data using his
  -  all users can access and share the project
  -  security: outsiders can access and edit the project
  -  git has (distributed repo )

*** TODO Q) git Vs SVN (Subversion)
SVN is centralised VCS , Git is distributed VCS
SVN is still used because of its performance with large files won't be satisfied with Git.
** short tutorial
- Creating a version control of local repository
  - We need to Create a version contol file (=.git=) it create by =git init=
    
#+BEGIN_SRC sh
     git init                                  # Inicialize or Create a version control 
     git status                                # View the Stagging Area
     git add <file>                            # Add files to stagging Area
     git add -A
     git rim --cached <file>                   # Remove files in Stagging Area
     touch .gitignore                          #  list all files  that are need to ignore                    # Ignore files in Stagging Area
     git commit -m "fist commit"               # Save-Commit  to Local Repo
     git remote add orgin https://github.com/....                      # Connect Local Repo to Remote Repo
     git push origin master                    # Upload Local Repo to Remote Repo
     git pull                                  # Update Local Repo
     git clone https://github.com/..git        # clone to current dir   # Clone
     git diff  <commit id> <commit id>         # diff : View changes in fiels

     ## Creat Branch ,push, delete:
     git branch <branch-name>       # create a new branch
     git chechout -b <branchname>    # to create and moveing to the   
     git branch                      # list of branch
     git branch --list               # list of branch
     git checkout UncleDaveEmacs     # Switch one branch to other
     git push -u origin UncleDavesEmacs  # push branch from local repo to remote repo
     git branch -D UncleDaveEmacs  # delete a branch
     git push orign <branch-name>     # push branch to remote repo
     git branch -D devop     # git delete a branch in local repository
     git push origin --delete <branch name>     # delete branch at remote repositort
     git push origin --delete UncleDaveEmacs # delete a branch in remote repository

     # Merge
     git chekout master # to go to destination (master)
     git merge <branch-name>     # merge brach to master git
#+END_SRC
** Installation and Configuration Cmd
#+BEGIN_SRC  sh
  git --version   # >> git version 2.3.2

  # Configuration 
  git config --global user.name "Dankarthik25"
  git config -global user.email "dankarthik25@gmail.com"

  # help
  git help config
  git config --help

  #
  cat ~/.gitconfig
  #[user]
  #        email = dankarthik25@gmail.com
  #        name = Dankarthik25
  #[log]
  #  date = relative
  #[format]
  #  pretty = format:%C(auto,yellow)%h%C(auto,magenta)% G? %C(auto,blue)%>(12,trunc)%ad %C(auto,green)%<(7,trunc)%aN%C(auto,reset)%s%C(auto,red)% gD% D
#+END_SRC

** TODO Q)three main states in git 
- Git has three main states that your files can reside in:
  - Working-Dir, Stagging Area, Local repo, Remote repo 
  - =Working-Dir=      File but have not have =Version Control= (committed)
  - =Stagging Area=    Marked a modified file  which are to be commit
  - =Committed=      Current files are commented/safed in local Repository =.git directory=.
  - =Remote Repository=
*** How to Commit files ? 
**** initialize  the file or local-repository  (git init):()
Create a version control folder or =initialize= or track (changes or versions) we have to initialize the folder 
#+BEGIN_SRC sh
# go the directory (Local-Repositore) that has to be version control 
git init
#+END_SRC

This will create a =.git= file in the current directory  which consist of all the change that are to be done
**** Adding files to git (git add file)
files which are uncommited are changed to =staged= 
#+BEGIN_SRC sh
git add <file>             # add files to git
git add -A                     # add all file
git status                     # show <file> or all file are change to commited area
#+END_SRC
***** Example:
#+BEGIN_SRC sh
git add .gitignore
git add .emacs
git add .vimrc
#+END_SRC
 =.gitignore=  which was in untracked () is changed to staging area or committed
**** Removing files from git (git reset file)
#+BEGIN_SRC sh
git reset <file>                     # remove  files from stating area( committed)
git reset                                  # remove all files
#+END_SRC
**** .gitignore
hidden file =.gitignore=  contain the list of the all the file and folder that ignore by git for version control
#+BEGIN_SRC sh
touch .gitignore
ls -a >> .gitigonre	# and remove the files need to be VC
#+END_SRC
***** Example
in file add the file or folders that are to ignored by git
#+BEGIN_SRC sh
# file that are to ignore
.DS_Store
.project
*.pyc
#+END_SRC
**** Commit files (git commit)
Note : All files are need to to add/ignored then only we can commit files
#+BEGIN_SRC sh
  git add -A
  git commit -m "Initial Commit"                        # file are commited 
  git status                                                                  # show nothing to commit , working directoru clean    
#+END_SRC
*** Connect Local Repository to Remote Repository
  #+BEGIN_SRC sh
git remote add origin url    # eg: git remote add origin https://github.com/dankarthik25/pythonUdemyTutorial  
  #+END_SRC
*** Push Local Repository to Remote Repository (git push)
#+BEGIN_SRC sh
git push origin master
# git push origin master -f     # Force if cmd not works
#+END_SRC
*** TODO Pull Remote Repository to Local Repository
#+BEGIN_SRC sh
git pull
#+END_SRC
** Clonning a repository
#+BEGIN_SRC sh
git clone <url> <path- which dir>
git clone ../remote_repo.git .
git clone <url> .                        # . means current direcory
#+END_SRC

** Q)Pull vs fetch
- In the simplest terms, git pull does a git fetch followed by a git merge.
- git fetch
  - Update your remote-tracking branches under refs/remotes/<remote>/.
  - No change in local repo/branch,Staging Area, Working Dir.
- git pull
  - Update your remote-tracking branches under refs/remotes/<remote>/.
  - Change local branch and Working Dir
    - Note: All the Untracked data will be lost in Working Dir
    - Note: merge only current branch wich it is pulled
      
#+BEGIN_SRC sh
# fetch hold data(fetch data from remote  repository to local repository)  r  but not merges with current reposiotory
git fetch
git merge # it merges local repository to current repository 

# pull
git pull origin <branch-name> # git fetch and git merge
#+END_SRC

** Creating a Branch (git branch <branch-name>)
source : https://nvie.com/posts/a-successful-git-branching-model/ 
#+BEGIN_SRC sh
    ## Creat Branch ,push, delete:
    git branch <branch-name>                  # create a new branch
    git branch UncleDaveEmacs       # Create a branch
    git branch                      # list of branch
    git branch --list               # list of branch
    git checkout UncleDaveEmacs     # Switch one branch to other
    git chechout -b <branchname>    # to create and moveing to the <branch-name>
    git push -u origin UncleDavesEmacs  # push branch from local repo to remote repo
    git branch -D UncleDaveEmacs  # delete a branch
    git push orign <branch-name>     # push branch to remote repo
    git branch -D devop     # git delete a branch in local repository
    git push origin --delete <branch name>     # delete branch at remote repositort
    git push origin --delete UncleDaveEmacs # delete a branch in remote repository
#+END_SRC
** log
Consist of < commit id, Author, Date, Comment on commit > 
 mode on your branch
#+BEGIN_SRC sh 
git log  # give <git id,author, date, commit message>
git log --online # give short version only < commit id, comment- message >

#commit 874357761ce77a9a925c1066d9cef6e81a5881a5
#Author: Dankarthik25 <dankarthik25@gmail.com>
#Date:   Fri Apr 10 06:56:16 2020 +0530

 #   Revised Docker

#commit 7432654c56923fe3bc18b19d7ac69e70300d86f4
#Author: Dankarthik25 <dankarthik25@gmail.com>
#Date:   Thu Apr 9 07:16:05 2020 +0530

 #   Seperate Docker_Kubernetics


#    my Notes on Prog
git log --oneline
# 70da939 (HEAD -> master, origin/master) New Change
# 53dd0ee New Change
# f537b27 New Change
# 432784e New Change
# 546bc17 Link and Compose added
# 8743577 Revised Docker
# 7432654 Seperate Docker_Kubernetics
# e981603 Seperate Ansible
# abb9dee last commit
# 9ab9c9a Added Ansible and Docker, Kubernetic files
# c39821d my Notes
# 370fca2 my Notes on Prog

#+END_SRC
** revert :
when code is pushed to remote but you want changes back from remote > local 
#+BEGIN_SRC sh
git log --oneline # to get the commit id

git revert 77592f3   # to change code frome to remote to local repo

# to change the code from local to remote we need to push from local to remote

git push origin master


#+END_SRC

** reset vs revert
*** Git reset
The git reset command allows you to RESET your current head to a specified state. You can reset the state of specific files as well as an entire branch. This is useful if you haven't pushed your commit up to GitHub or another remote repository yet.
*** Three types of reset 
  |---------------+----------------------------------------------------------------------|
  | Type of reset | Description                                                          |
  |---------------+----------------------------------------------------------------------|
  | soft          | keep all changes in stagging area, remove from local repo            |
  | mixed         | keep all changes in workind dir, remove from stagging and local repo |
  | hard          | removes all changes from local repo,stagging and local repo          |
  |---------------+----------------------------------------------------------------------|
 
- In the simplest terms:
  
| Type of reset | Workdir          | Stagging Area          | Local Repo | git log | Remote Repo |
|---------------+------------------+------------------------+------------+---------+-------------|
| soft          | Prescent         | moved to Stagging Area | Removed    | Removed | Prescent    |
| mixed         | Moved to Workdir | Removed                | Removed    | Removed | Prescent    |
| hard          | Removed          | Removed                | Removed    | Removed | Prescent    |
|---------------+------------------+------------------------+------------+---------+-------------|

*** TODO revert (Need to check if revert altering history of commits)
Both the git revert and git reset commands undo previous commits. But if you've already pushed your commit to a remote repository, it is recommended that you do not use git reset since it rewrites the history of commits. This can make working on a repository with other developers and maintaining a consistent history of commits very difficult.

Instead, it is better to use git revert, which undoes the changes made by a previous commit by creating an entirely new commit, all without altering the history of commits.


#+BEGIN_SRC sh
  # delete file in local and remote repo

  # To remove file for remote to  
  git revert <commitid> 
  git commit - m "remove from remote"

  got log --oneline

  #commit id : 1
  #commit id : 2
  #commit id : 3
  #commit id : 4
  #commit id : 5
  git reset --soft 2 # keep the commit after 2 (3,4,5) 
  #commit id : 3
  #commit id : 4
  #commit id : 5


  git reset --hard 77592f3  # 
  git reset --soft 77592f3  # local repo to stagging 
  git reset --mixed 77592f3 #  local repo to work - dir

  git log --oneline
  # beef857 Revert "created test3 file"
  # 77592f3 created test3 file
  # 1c08f78 created test2 file
  # 78b777d created test1 file
  # a7968c1 Created hh
  # 4b30445 Created bb
  # 2e435ca Created gg file to intall git

  git revert 1c08f78
  git push origin master
#+END_SRC
** Git branching Modeling
 If your team is doing continuous delivery then it is suggested to follow Git branch model. Here is a simple version of it
https://nvie.com/posts/a-successful-git-branching-model/

At the core, the development model is greatly inspired by existing models out there. The central repo holds two main branches(master(origin) , developer)
with an *infinite lifetime*:
- master :
  We consider origin/master to be the main branch 
- develop:
  When the source code in the develop branch reaches a stable point and is ready to be released, all of the changes should be merged back into master somehow and then tagged with a release number.

  Therefore, each time when changes are merged back into master, this is a new production release by definition. We tend to be very strict at this, so that theoretically, we could use a Git hook script to automatically build and roll-out our software to our production servers everytime there was a commit on master

  Any feature branch from develop Must merge back into develop. feature branches are limited time branch which will eventually merged back to develop branch
   
- Supporting branches:
  Development model uses a variety of supporting branches to aid
  - parallel development between team members,
  - ease tracking of features,
  - prepare for production releases and to
  - assist in quickly (bug)fixing live production problems.
    
  Unlike the main branches, these branches always have a *limited life time*, since they will be removed eventually.

The different types of branches we may use are:
  - feature
    Any feature branch from develop Must merge back into develop. feature branches are limited time branch which will eventually merged back to develop branch 

    naming convention:anything except master, develop, release-*, or hotfix-*
     
    Feature branches (topic branches) are used to develop new features for the upcoming or a distant future release.
    When starting development of a feature, the target release in which this feature will be incorporated may well be unknown at that point. The essence of a feature branch is that it exists as long as the feature is in development, but will eventually be merged back into develop (to definitely add the new feature to the upcoming release) or discarded (in case of a disappointing experiment).
    
  - release branch
    Any Release branches from develop and Must merge back into develop and master. naming convention(release-*)
    - Release branches support preparation of a new production release.
    - Allow for minor bug fixes and
    - preparing meta-data for a release (version number, build dates, etc.).
      
    By doing all of this work on a release branch, the develop branch is cleared to receive features for the next big release.

    The key moment off a new release branch when
    - atleast all features that are targeted for the release-to-be-built must be merged in to develop at this point in time.
    - All features targeted at future releases may not—they must wait until after the release branch is branched off.
      
  - hotfix(BUG-fix)
    Any hotfix branch from master Must merge back into develop and master
    naming convention:hotfix-* 

    They arise from the necessity to
     - act immediately upon an undesired state of a live production version.
     - When a critical bug in a production version must be resolved immediately, a hotfix branch may be branched off from the corresponding tag on the master branch that marks the production version.

     The essence is that team members (on the develop branch) can continue, while another person is preparing a quick production fix.
     
** merge
#+BEGIN_SRC sh
git checkout master # to git <branch-name>
git merge devop # git merge <other-branch-name>

##  Example 

# create nn file in "devop"  branch
git checkout devop
touch nn
git add .
git commit -m "created nn file"
git push  origin devop

# merge "devop" branch to  "master branch"
git chekchout master

#+END_SRC
** TODO merge vs rebase vs cherrypick
git merge :
- Is a non-destructive operations
- Existing branes are not change in any way
- Create new <commit-id> in original(main) branch
- Normal merge changes history and squash merge will not change history all original but new commit-id is created .

git rebase:
- Moves the entire 2nd branch to main branch
- Re-writes the project history
- We get much cleaner and linear project
    
git cherry-pick:
- Add specific <commit -id>  to 1st branch 
- For cherry-pick add particular <commit -id>
#+BEGIN_SRC sh
git checkout master
touch aaa
git add aaa
git commit -m "created aaa file in master"

git checkhout -b "release-1.0"
git rebase master
#+END_SRC

*** cheery pik
Not all commit id in branch are merged in main branch
but selected commit id are merged in main branch

#+BEGIN_SRC sh
git checkout -b future
touch ww
git add .
git commit -m "create ww file"
touch ww

touch www
git add .
git commit - m "create www file"


touch wwww
git add
git commit - m "create wwww file"

touch wwwww | git add .
git commit -m "create wwwww file"

git log --online 
# c459d7a created wwwwww file
# b866590 created wwwww file
# b510fa6 created www file
# b6b5153 created ww file
# 9d75eb8 created aaa file in master
# 7fb9174 created file called mm

# Q) merge only www file from future brach to master
git log --online # to get the <commit -id> of www file : b877590

git checkout master

git cherry-pick b877590
git log --online 
# b866590 created wwwww file
# 9d75eb8 created aaa file in master
# 7fb9174 created file called mm

#+END_SRC
** conflicts
When two branch <kar> <sanjay> make different change in a same file 
#+BEGIN_SRC sh
git checkout master
vi ww
# hello

git add  .
git commit -m "modified ww file"

git log 

git checkout future
vi ww
# hello,
# book ticktes

git commit -m "modifiled ww file"

git checkout master

git merge future 
#ERROR mESSAGE: CONFLICT (content): merge confilct in ww
#             : fix conflicts and then commit the results
vi ww

#+END_SRC

** Interview Qusestion
- Q)If branch and merge, and pull and push  are done my devops then what is role of devops 
- Ans) devops role is to create hotfix branch and and set a maile to devops  
*** what is use of git 
- to  track all changes in file or directory in VCS [Version Control System]
- can not lose data -delete -revert
- all users can access and send data
*** Different type of vcs
- cenrtal vcs svn
- distributed vs : github or bitbucket
** TODO Q) fork and clone
* maven
** What is maven 
      - Maven is a *java base build tool* which help developers to build (Projects) or  create *artifacts* (jar, war, ear)
         - jar java archive,
         - war web archive ,
         - ear enterprise archive
      - A built tool is used to automate everything related to building the software project.
      - Why Maven ?
        -  Maven comes with POM, most of prj has to use 3rd patry library which also updates with time for this we need our team to share  dependencecy  info(documentation) and all developer need to maually config Prj with this dependencies. But with POM all the dependencecy automate so developers need not spend time conf and documenting 3rd parties or dependencecy.
                    
      - is a *project management  tool* based on concept of Project Object model(POm) which can  manage 
          - project build
          - reporting and 
          - documentation for central piece of information
** TODO Difference btw jar war ear
** Why developers use maven ?
Developers using maven because it provide
  - a standard way to build  the project
  - a clear defination of what  the project consisted of 
  -  an easy way to publish project infor and a 
  - way to share/deploy JAR across serveral  projects
  
** maven repository
- Maven has three repos
  - Local Repo (dir by name .m2 local os where maven is installed )
  - Central Repo (Internet): Created and maintained by apache maven community 
  - Remote Repo (In general for  custome repository  jfrog artifactory is used)
** Why we need maven repo ?
When we run =mvn archetype:generate= it serach for all dependencies in local,central,remote repo and then move them to local repo for next execution
** What is POm.xml
- Contains information about dependencies,project and configuration details used by maven to build project 
- Pom consits of 
  - Description
  - Name and Version, Artifact Type, Source Code Location, Dependencies
  - Plugins
  - Profiles

** Install of maven
*** extract maven
#+BEGIN_SRC sh
# Download maven in /temp using wget
wget wget https://mirrors.estointernet.in/apache/maven/maven-3/3.6.3/binaries/apache-maven-3.6.3-bin.tar.gz -P /tmp
# extract the archive to /opt directory
sudo tar xf /tmp/apache-maven-*.tar.gz -C /opt
#  more control over maven version and update we will create a symbolic link<maven> that will point to maven installation directory
sudo ln -s /opt/apache-maven-3.6.0 /opt/maven
#+END_SRC
https://linuxize.com/post/how-to-install-apache-maven-on-ubuntu-18-04/

*** Setup environment variable
#+BEGIN_SRC sh
# Open mavenenv.sh in /etc/profile.d dir
sudo nano /etc/profile.d/maven.sh

# add environment variables
export JAVA_HOME=/usr/lib/jvm/default-java
export M2_HOME=/opt/maven
export MAVEN_HOME=/opt/maven
export PATH=${M2_HOME}/bin:${PATH}
# save and close the file 

# change mod of maven to execute
sudo chmod +x /etc/profile.d/maven.sh

# load the environment variable using source command
source /etc/profile.d/maven.sh

# verify the installation
mvn -version
#+END_SRC

** Build server: 
Build server job is take the code from git and build artifact (jar,war, ear )
#+BEGIN_SRC sh
mvn archetype:generate # Need 3 input : group Id, version, artifact Id
#+END_SRC
  
** Create maven project
#+BEGIN_SRC sh
cd /Workspace/Devops # Directory for maven project here pom.xml file

mvn archetype:generate -DgroupId=world -DartifactId=india -DarchetypeArtifactId=maven-archetype-webapp -DinteractiveMode=false
# [INFO] ----------------------------------------------------------------------------
# [INFO] Using following parameters for creating project from Old (1.x) Archetype: maven-archetype-webapp:1.0
# [INFO] ----------------------------------------------------------------------------
# [INFO] Parameter: basedir, Value: /home/jayradhe/Workspace/Devops
# [INFO] Parameter: package, Value: world
# [INFO] Parameter: groupId, Value: world
# [INFO] Parameter: artifactId, Value: india
# [INFO] Parameter: packageName, Value: world
# [INFO] Parameter: version, Value: 1.0-SNAPSHOT
# [INFO] project created from Old (1.x) Archetype in dir: /home/jayradhe/Workspace/Devops/india
# [INFO] ------------------------------------------------------------------------
pwd
# ~/Workspace/Devops
ls
# india |- src    # india : ArtifactId
#       |-pom.xml 

 # Developers put there code in and push it to github
# artifact_Id/src/main/java/group_Id

# Pull the code and build artifact
maven comple
maven package
maven install
maven deploy

#+END_SRC
** Maven Lifecycle and 8  Phases
In general maven lifecycle has 8 phases: [Need to visit : javatpoint.com maven-life-cycle: 8items=> validate,test,clean  ]
- validate          : all necessary information is available and validate the project is correct.
- compile           : compile the source.
- test              : test the compiled source using  unit testing framework. 
- package           : take the compiled code and package it in its distributable format, such as a JAR,war
- intergration test :
- verify            : run any checks on results of integration tests to ensure quality criteria are met
- install           : install the package into the local repository, for use as a dependency in other projects locally
- deploy            : copies the final package to the remote repository for sharing with other developers and projects.
#+BEGIN_SRC sh
# hello.java 
mvn clean # clean of 
mvn complie  #  To compile     
mvn test-compile
mvn test 
mvn package   # To create a package
mvn install   # Copy Package to local repos (.m2) with dependency  # create a .war file
mvn deploy    # deploy to (remote repo)


hello.class -compile -mvn compile #
# TO create a package 
mvn package  
#+END_SRC

** Integrate Maven with git
- Step 1: OPS : Create git repo and send to all dev
- Step 2: DEV : clone the repo,create (src, pom.xml) and  push code into github 
- Step 3: OPS : clone the repo,Build artifacts (war file: mvn package)
- Step 4: OPS : push(scp) war file  to dev,sit,preproduct, prod servers

#+BEGIN_QUOTE
- Developers will create maven file and in src file they will uploade developer code and push code to github
- OR
- Developerss will 1st create a maven project and then it will write the code then they will version control (git) and upload them th remote repository (github)
*Note* :For Continous Testing & Deployment:  We need to deploy the artifacts to different envirnoment (development, sit (System Integration and Testing),uat (User Acceptance Testing),prod)
#+END_QUOTE

#+BEGIN_SRC sh
mvn archetype:generate -DgroupId=world -DartifactId=india -DarchetypeArtifactId=maven-archetype-webapp -DinteractiveMode=false

#tree -L 1
#LG
#|- india/
#|     |-  src/
#|     |-  pom.xml
#|
#|- READ.md



#- Step 1: OPS : Create git repo and send to all dev
#- Step 2: DEV : clone the repo
#- Step 3: DEV : push code into github (contain src and pom.xml in github)
# Above all code is writen by developers with devops are also present
git add india
git commit -m "created mvn project"
git push origin master

#
#  How to create war file for github
#
git clone https://github.com/kliakos/sparkjava-war-example.git
cd sparkjava-war-example

#- Step 5: OPS : Build artifacts (war file: mvn package)
mvn install  # will create a war file 


#+END_SRC

#+BEGIN_SRC sh
#!/bin/bash

#- Step 6: OPS : push(scp) war file  to dev,sit,preproduct, prod servers

src=india/target/web.war
dest=/opt/
env=$1
if [$env=='sit']
then
   scp $src@192.124.24.5:$dest
fi

#+END_SRC
** Question and Answer
- Q)Who create src file and pom.xml file ?
  - =mvn archetype:generate -DgroupId=world -DartifactId=india -DarchetypeArtifactId=maven-archetype-webapp -DinteractiveMode=false= create src dir and pom.xml
  - maven is a project management tool and we need 3 argument: group Id, Artifact Id, Version
- Q) What is actually pom.xml  file
  - Consist of 
    - group Id, 
    - artifact Id, 
    - version
    - dependency-links
    - Link to remote repository 
- Q)For running maven cmd (compile,package,install,deploy)  why it should present in the same directory where pom.xml is present
- Q)why we use build tool 
  - Ex) To build artifacts(jar,ear,war)(java artive,web archive, enterpashilp archive)
- Q) Why it is called maven life cycle ?
  - Ex if we need to run install : we need to go step by step like compile, package, install
- Q) What is difference between Snapshot and Version ?
  - Snapshot : For every realased snapshot is increased or updated.
  - But version is different it not updated or increased for every deployment but for final-deployment Version is updated.
- Q) What is =maven archtype:generate= ?
  - It is a maven plugin use to generate src and pom.xml file
- Q) how to ignore test cases in maven ?
  - mvn install -DskipTests
** Q) how to create multi module project 
  - parent pom - superpom
  -     child pom


parent pom.xml file
sbi/pom.xml           # super pom
├── India/pom.xml     # child pom
├── AP/pom.xml        # child pom 
└── Hyderabad/pom.xml # child pom

#+BEGIN_SRC xml
<packaging>pom </packaging>
<modules>
<module>India/pom.xml</module>
<module>AP/pom.xml</module>
<module>Hyderabad/pom.xml</module>
 </modules>

#+END_SRC

** Q)how to use profiles
A) to set of configuration file
profile
dev/application
sit
pre production
production

tomcat jboss weblogics
war     ear     cluster :dev1 dev2 dev3

jar micro-servies 

* Servers (Tomcat) 
** Introduction
Server contains: 
  - Start and shutdown programs (irctc ticket booking at night 12am)
  - Can be supported to run war or ear files continously
     Ex: sbi.war is copied in to server then sbi site is opend

Type of Servers
 - Webservers - Eg: apache tomcat 
    -  it can be supported only war file it wont support ear files
 - Application Servers : jboss
   - it can be supported  ear file
 - Cluser: 
   - web logics
   - group of servers
   - support ear files  



# By default tomcat server is 8080 
# We can change server in conf/server.xml - conncetor port
# After starting if there is some error then check log file

we are using tomcat 9 server there is 10 but 10 is alpha and 9 is stable version
** Deployment process

tomcat9/ 
├── bin                  # start and shutdow files 
├── config               # default port:8080
|       └── server.xml   # to change port Number
├── log                  # If server is not working check logs
└── webapps              # all jar,war files are moved from maven

Deployment Process
- Stop the server process
- take required backups sbi.war-> sbi.war'data'.zip
- Deploy sbi.war(build server (scp * .war $user@$ip :opt/apache-tomcat-9.0.16/webapps/*.war )
  - Deployed to dev,sat,uat,pre-production,production ((development, sit (System Integration and Testing),uat (User Acceptance Testing),prod))
- start the server
- check it in web browser

** installation
https://www.youtube.com/watch?v=Feui5F42bII
#+BEGIN_SRC sh
  # cd Workspace/Devops/tomcat # directory where tomcat is install 
  # get link for tomcat 9 tar file
  wget https://mirrors.estointernet.in/apache/tomcat/tomcat-9/v9.0.31/bin/apache-tomcat-9.0.31.tar.gz


  # extract tar file
  tar -xvzf apache-tomcat-9.0.31.tar.gz

  # install java file # /software/jdk1.8.0_131
  vi ~/.bashrc

  # insert below text
  # JAVA ENVIRONmENT VARIABLES
  export CATALINA_HOME=~/Workspace/Devops/tomcat
  export JAVA_HOME=/usr/lib/jvm/default-java
  # cd /usr/lib/jvm ;ls -l # choose any one from it  
  # run bash
  source ~/.bash_profile

  cd Workspace/Devops/tomcat
  sh startup.sh

  # Run tomcat server
  sh /home/jayradhe/Workspace/Devops/apache-tomcat-9.0.31/bin/startup.sh

  # Stop tomcat server
  sh /home/jayradhe/Workspace/Devops/apache-tomcat-9.0.31/bin/shutdown.sh


  ## Create symbolic link 
  #ln -s /opt/tomcat/apache-tomcat-9.0.31/bin/startup.sh /usr/local/bin/tomcatup
  #ln -s /opt/tomcat/apache-tomcat-9.0.31/bin/shutdown.sh /usr/local/bin/tomcatdown

  ## To start tomcat as root anywhere in shell
  #tomcatup
  ## To stop tomcat
  #tomcatdown

  sudo ufw allow 9090
  firefox localhost:9090 # By default tomcat server is 8080 
  # We can change server in conf/server.xml - conncetor port
  # After starting if there is some error then check log file
#+END_SRC


** Change Port Number
*** Tomcat File system
#+BEGIN_SRC sh
Tomcat
├── bin  # executable file : start up and shutdown
├── conf # server.xml : change config 
|     └──server.xml # like port by default port is  :8080
├── log    
└── webapps 
      └── sbi.war 
#+END_SRC
*** Edit server.xml 
#+BEGIN_SRC sh
cat server.xml
######################################################
# Change port :8080 
<Connector port="8080" protocol="HTTP/1.1"
               connectionTimeout="20000"
               redirectPort="8443" />

#+END_SRC
** Configure the Tomcat Web Management Interface

Follow the command below to add a login to your Tomcat user and edit the tomcat-users.xml file:
#+begin_src 
sudo nano /opt/tomcat/conf/tomcat-users.xml
#+end_src
Now, define the user who can access the files and add username and passwords:
#+begin_src xml
<role rolename="manager-script"/>
<role rolename="manager-gui"/>
<user username="tomcat" password="tomcat" roles="manager-script,manager-gui" />
#+end_src

** install using apt-get 
https://www.youtube.com/watch?v=26ipmonPmRw
#+BEGIN_SRC sh
sudo apt-get install tomcat9-docs
sudo apt-get install tomcat9-examples
sudo apt-get install tomcat9-admin
sudo start tomcat9
sudo status tomcat9
sudo service tomcat9 stop
sudo status tomcat9
#+END_SRC

** Example 
SampleWebApp.war file
https://www.middlewareinventory.com/blog/sample-web-application-war-file-download/
#+BEGIN_SRC sh
# download  or SampleWebApp.war file to tomcat/webapps dir # 
# /home/jayradhe/Workspace/Devops/apache-tomcat-9.0.31/webapps


#+END_SRC

** Example 2
https://github.com/kliakos/sparkjava-war-example

#+BEGIN_SRC sh 
# get clone to local repository
# cd /home/jayradhe/Workspace/Devops # local repository
git clone https://github.com/kliakos/sparkjava-war-example.git

#+END_SRC
** TODO Deploy war file to tomcat
#+BEGIN_SRC sh
#!/bin/bash
env=$1
if[$env='dev']
then 
scp sbi.war dev@192.145.67.8: tomcat/webapps
fi

#+END_SRC
** How to Deploy (automate) git code to tomcat server  [029 Udemy Lecture]
- Steps required
  - Configure Tomcat or Create User for remote acess
  - Create Job to Produce Tomcat Deployable Artifacts
  - Install "Copy Artifact" & "Deploy to Containers" Plugins
  - Create Job to Deploy Artifacts to Tomcat server or(Staging Env).
*** Configure Jenkins with Tomcat for Auto Deployment of Artifacts.
#+BEGIN_SRC sh
  cd /opt/tomcat/conf
  # update tomcat-users.xml file
  # roles : manger-script & manger-gui
  # Set password:tomcat

  #  <role rolename="manager-script"/>    # tomcat manage, jenkins
  #  <role rolename="manager-gui"/>
  #  <user username="tomcat" password="tomcat" roles="manager-script,admin-gui" />
  #</tomcat-users>


  # Restart the tomcat server
  /opt/tomcat/bin/shutdown.sh
  /opt/tomcat/bin/startup.sh

#+END_SRC
*** Create Job to Produce Tomcat Deployable Artifacts
#+begin_quote
Create a view :
View Name : _TomcatDeploy_View_
List View : select

Inside "TomcatDeploy_View" Create a New JOB   :
New item > Name _Package_Application_
Genral :        
    Description: This Job is Packaging Java-Tomcat-Sample Project  and Create war file
    Discard Old Build: 5 days and 5 builds
Source Code management:
    git :https://github.com/anshulc55/Jenkins_Upgradev3.git 

Build Trigger :
    Poll SCm: * * * * *
Build: _Invoke top-level maven target_
    pom : _location of pox.xml_

Post-build Action : _Archive the artifacts_
    Files to archive : _**/*.war_

Post-build Action : _Build Other Project_
    Project to build : _Depoly Application Staging Env_ (Below Stage Job Name)
    Trigger only if build is stable : Ok
Save Job
#+end_quote

*** Create Job to Deploy Artifacts to Tomcat server or(Staging Env)
#+begin_quote
Step 1:  Install "Copy Artifact" & "Deploy to Containers" Plugins
Step 2:
New item > Name : _Depoly Application Staging Env_
           FreeStyle
Genreal:
     Description : This Will Deploy the Java_Tomcat_sample in Staging Enviroment
     Discard Old Build : 5 days , 5 build
Build:
     _Copy Artifacts from Another Project_
     Project Name :  _Package_Application_   (Project Name for above Prj)
     Artifacts to Copy :  _**/*war_

Post-build Action
   _Deploy war/ear to a container_
    War/Ear files : _**/*.war_ 
    Context Path : _/_
    Containers : _Tomcat 9_
    Credentials : Add credentials 
             Username : tomcat
             Password : tomcat (For configuration we set)
    Tomcat Url : Same page url.
#+end_quote    
* Jenkins 
- Jenkins 
  - installation
  - how to create jobs
  - checkout git
  - goal package
  - send a mail
  - archive powershell scripts
  - execute powershell scripts
  - permission 
  - upstream and downstream - 
  - pipeline(build)
  - master-slave 
  - dependencies
  - distribution
  - Countious Integration (CI)
  - Countious Development
  - backup
  - build triggers (poll SCm)
    
** TODO [02nd march]-installation
- Jenkins can be install in 3 ways
  - 1. using executal file (unzip and install)
  - 2. using java    (java -jar jenkins.war)
  - 3. inside tomcat (jenkins.war files) 
    - install tomcat then copy jenkins.war to tomcat/webapps
    - run tomcat start and open https://localhost:8080/jenkins
  - 4.Install inside VM : Vagrant
  - 5. Install inside docker      
*** Using zip file
#+BEGIN_SRC sh
# Install java(jenkins is java 8 app) so install openjdk
sudo apt update
sudo apt install openjdk-8-jdk
 
# add Jenkins debian repository 
wget -q -O - https://pkg.jenkins.io/debian/jenkins.io.key | sudo apt-key add - 
# above cmd  should output OK which means that the key has been successfully imported and packages from this repository will be considered trusted.

# add Jenkins repository to sys 
sudo sh -c 'echo deb http://pkg.jenkins.io/debian-stable binary/ > /etc/apt/sources.list.d/jenkins.list'


# install jenkins
sudo apt update
sudo apt install jenkins # automatically run jenkins

# check running status of jenkins server 
systemctl stauts jenkins

# start jenkins
sudo systemctl start jenkins

sudo service jenkins restart
sudo service jenkins stop
sudo service jenkins start

# OR : alternate
sudo systemctl start jenkins.service
sudo systemctl stop jenkins.service
sudo systemctl restart jenkins.service

# Open Firewall
sudo ufw allow 8080

# set Wrokspace



# give administator password from : ..../Jenkins/secrets/initialAdminPassword file
sudo cat /var/lib/jenkins/secrets/initialAdminPassword
# select <install suggested plugins>

# sign in to jenkins 
user     : admin
password : /Jenkins/secrets/initialAdminPassword

create user : dankarthik
passwrod : dankarthik
 
#+END_SRC
*** Install jenkins in tomcat
#+BEGIN_SRC sh
cd /opt/softwares/apache-tomcat-9.0.31/webapps
 
wget https://updates.jenkins-ci.org/download/war/2.204/jenkins.war

tomcatdown
tomcatup

#+END_SRC
*** Install using java
#+BEGIN_SRC sh
java -jar jenkins.war
java -jar jenkins.war --httpPort=9090
#+END_SRC
*** Configure  Port 
In case you want to change the default jenkins port on Linux,
You can go to /etc/default/jenkins  
add --httpPort=9999 or whatever port to JENKINS_ARGS
#+BEGIN_SRC sh
vi /etc/default/jenkins
# # port for HTTP connector (default 8080; disable with -1)
# HTTP_PORT=8080

#+END_SRC

** Plugis update, install, advance
Notee: only java 8 is able to link with jenkins not default-java or java 11....etc

** Plugis :
Manage jenkins > manage plugis
[update,avaiable,installed,customed]
- Plugins
  - If there is No execute powershell in build then install 
    - Manage jenkins > manage plugins > avaiable > search powershell
      - and install
  - *Maven Integration* deep integration, Automatic trigger btw prj depending on SNAPSHOTS, automated config of Junit....etc
         
** 1st Jobs build periodically
(menu)Jenkins > New Items > FreeStyles >

- General
  - Discard odl builds : Remove  the old build
      - Days to keep builds    :__________
      - max # of build to keep :__5________
  - GitHub Project 
      - give url for source code: ____give github http clone link___https://github.com/dankarthik25/my-app.git _  # Note should consist of pom file
- Source Code management
- Build Triggers
   - Build Periodically 
#+BEGIN_SRC sh
# * * * * *  # build for every minite
#+END_SRC  
** Job Build Trigger remotely(from scripts, url)
- Build is done using url or script

htttp:localhost:8008/job/FirstJob/build?token=dkarthik25
#+begin_quote
- General
- Source Code management
- Build Triggers
   - Trigger build remotely (eg., from scripts)
     TOKEN_NAME: dkarthik25
#+end_quote
htttp:localhost:8008/job/FirstJob/build?token=dkarthik25

** DONE [03rd march] Createing 1st job
Create 1st   


|-------------------+-------------------------------------|
| New Item          | Create a job or project             |
|-------------------+-------------------------------------|
| People            | User which are connected to Jenkins |
|-------------------+-------------------------------------|
| Build             | Build                               |
|-------------------+-------------------------------------|
| manage Jenkins    | manage                              |
|-------------------+-------------------------------------|
| my views          |                                     |
|-------------------+-------------------------------------|
| lockable resource |                                     |
|-------------------+-------------------------------------|
| credentials       | Create Credentials                  |
|-------------------+-------------------------------------|
| new view          |                                     |
|-------------------+-------------------------------------|

(menu)Jenkins > New Items > FreeStyles >  
#+begin_quote
- General 
  - Description
  - Discard odl builds : Remove  the old build
      - Days to keep builds    :__________
      - max # of build to keep :__________
  - GitHub Project 
      - give url for source code:________
  - TODO :Build requires lockable resource

  - Project is parametrized :
         : Project require agruments to be passed 
  - Throttle builds   # No.of Concurrent(parallel) build

      
- Source Code management
   Git : url_________ 
   Subversion:


- Build Triggers
   - Trigger Build remotely: using url or (Authentication Token)

   - Build after other project are build :

   - Build Periodically 
#+BEGIN_SRC sh
# * * * * * 
#+END_SRC  
    - Github hook for GIT_SCm Polling
    - Poll SCm
     
- Build Environment
  - Delete Workspace before build starts (discard old build result and start fresh build)
  - Use secret text or file
         - password protection
    - Abort build if it's stuck
    - Inspect build log for published Gradle build scans
- Build
   - Execute shell
   - Execute Powershell
   - 

- Post-build Actions
  - E-mail Notification
  - Editable Notification
  - Git Publisher
  - Set Github commit status
  - Delete workspace when build is done



Build a job
Double Click Project > Build Now

#+end_quote
** DONE [07 march]Integrating with gmail
how to send an email to other ?
 - why should i share user and pwd to other client,middle-men, higher secured so we need to configure  and we send only log file to client,manager...etc
#+BEGIN_SRC
step1: 
manage jenkins - 
    configure system - 
       Extended email notification: # New version is released need research
          SmTP server                  : smtp.gmail.com
          Default user E-mail suffix   : @gmail.com
          Use SmTP Authentication      : Check-Ok
          Username                     : sanjy@gmail.com
          passwd                       :
          Use ssl                      : Check-Ok
          SmTP port                    : 456

       E-mail Notification:
          SmTP server                  : smtp.gmail.com
          Default user E-mail suffix   : @gmail.com
          Use SmTP Authentication      : Check-Ok
          Username                     : sanjy@gmail.com
          passwd                       :
          Use ssl                      : Check-Ok
          SmTP port                    : 456
          Test configuration by sending test e-mail: Check-ok

step2: go to google account -> security-> on less security 
test:


go to job:
post build actions 
       editable email notification :
            Project From            : jenkins
            Project Recipient List  : cc:omshiva003@gmail.com
            Attach Build Log        : Attach Build Log
            Content Token Reference : Advance
                               Trigger : Always (Always form Add Trigger)
Save
Build now 

#+END_SRC
** TODO [09 march]Permissions Add-Users Account (Role Based management) 
Steps 1 :
- Install Plugins
  Manage jenkins > manage plugis >avaiable
   - "Role-based Authorization Strategy",
   - "matrix based authentication"   default-installed
   - "Project based Authentication"  default-installed 

  Step 2: Create Users
- Manage jenkins > Manage Users > Create Users
  - Username : sanjay
  - Password :
  - Confirm password:
  - Full name :
  - E-mail address:
  Create User

*** Enable matrix based Security
- Step : Enable matrix based Security 
  - Manage jenkins - 
    - Configure Global Security -
      - Matrix-based security : enable
        - add users {phani,sanjay...etc} to matrix
          - Note : give all permission to root user

|User/group        |  Over all      |  Credentials                                      |
+------------------+----------------+---------+--------+----------------+--------+------+
|User/group        |Adminster| Read |  Create | Delete | mangae Domains | Update | View | 
+------------------+---------+------+---------+--------+----------------+--------+------|
|Authenticated User|         |      |         |        |                |        |      |
+------------------+---------+------+---------+--------+----------------+--------+------|
|admin             |         |      |         |        |                |        |      |
+------------------+---------+------+---------+--------+----------------+--------+------|
|sanjay            |  check  |check |         |        |                |        | check|
+------------------+---------+------+---------+--------+----------------+--------+------|

*** Project based
- Step :
  - Enable Project based Security :{Manage jenkins>Configure Global Security>Project based security : enable}
  - Create Project with Project based Security Enable
    - New item > Name: Phani-Project >  Free Style Based >General :Enable Project based Security
    - add users {phani,sanjay...etc} to matrix
      - Note : give all permission to root user

|User/group        |  Over all      |  Credentials                                      |
+------------------+----------------+---------+--------+----------------+--------+------+
|User/group        |Adminster| Read |  Create | Delete | mangae Domains | Update | View | 
+------------------+---------+------+---------+--------+----------------+--------+------|
|Authenticated User|         |      |         |        |                |        |      |
+------------------+---------+------+---------+--------+----------------+--------+------|
|admin             |         |      |         |        |                |        |      |
+------------------+---------+------+---------+--------+----------------+--------+------|
|sanjay            |  check  |check |         |        |                |        | check|
+------------------+---------+------+---------+--------+----------------+--------+------|
*** Role based Authentication
- Step 1 : Enable Role based
#+BEGIN_SRC sh
Enable Role-based Authorization Strategy

  Manage jenkins - 
      Configure Global Security - 
           Matrix based authentication: 
           Project based authentication: 
           Role-based Authorization Strategy : enable


#+END_SRC

- Step 2: Create and Assign Role
  - Step 3: Create Role :
    - Manage Jenkins >manage and assign roles >manage roles :
      -create roles like manager (create,delete,build,developer(read,create),tester (read) )

|Role              |  Over all      |  Credentials                                      |
+------------------+----------------+---------+--------+----------------+--------+------+
|User/group        |Adminster| Read |  Create | Delete | mangae Domains | Update | View | 
+------------------+---------+------+---------+--------+----------------+--------+------|
|Authenticated User|         |      |         |        |                |        |      |
+------------------+---------+------+---------+--------+----------------+--------+------|
|admin             |         |      |         |        |                |        |      |
+------------------+---------+------+---------+--------+----------------+--------+------|
|dev               |         |check |Create   |        |                |check   | check|
+------------------+---------+------+---------+--------+----------------+--------+------|
|test              |         |check |         |        |                |        | check|
+------------------+---------+------+---------+--------+----------------+--------+------|
      - Assign Role:
        - Manage Jenkins >manage and assign roles >assign roles :
          - add users(sathish,sanjay,venkat,karthik) to roles
| manage role | admin | dev   | manager | test  |
|-------------+-------+-------+---------+-------|
| admin       | check |       |         |       |
| sathish     | check |       |         |       |
| sanjay      |       | check |         |       |
| venkat      |       |       | check   |       |
| karthik     |       |       |         | check |
|-------------+-------+-------+---------+-------|
*** TODO Difference matrix-based Vs Project based Vs Role Based
*** TODO LDAP  and Active Directory
Jenkins new users and there authentication is done in local linux using ldap and active directory 
**** LDAP
#+begin_src 
yum isntall ldap

devopers - 4851,2458,9563,245697,24566,25665,
mangaer= 4582.31287,1258652
tester= 4521,324522
[/jenkins]
@devopers=r
@manager=rw
@tester=r

[\git]
@devopers=r
@manager=rw
@tester=r
#+end_src

**** Active Directory
Install Active Directory Plugin
- Manage jenkins - 
  - Configure Global Security -
    - Active Directory
      - Add Domain :

** TODO [12 march]Upstream and Downstream
There are diffrent job and jobs should be executive in order respectively
- world job
- india job
- hyd  job 
How do we auto-mate three jobs in order respectively
*** Create Jobs and pipline the jobs
For World job , {india,hyd} job are downstream and World in upstream
- Create world,india,hyd job 
- Pipeline Job :
  - Job : india job 
    -  Build Triggers :
       - Build after project are build
         - Projects to watch : _________world________
           - Trigger only if build is stable
  - Job : hyd job 
    -  Build Triggers :
       - Build after project are build
         - Projects to watch : _________india________
           - Trigger only if build is stable
             


*** To View Pipeline
- Step 1: Install "Build Pipline Plugin"
  - manage jenkins > manage plugins > install Build Pipeline
- Step 2 : Create a View Pipeline
   - Create a View{Name:Earth} > Build Pipeline View: Ok
   - Inside:localhost:8080/view/Earth/configure
     - Pipeline Flow: 
       - Select Initial Job: world
     - Trigger Options
       - Restrict trigger to most recent successful build : yes
       - Always allow manual tigger on pipeline steps : yes
 - Step 3: Save and apply changes          


*** Example
git [trigger build by change in git-code]
maven [build the code]
deploy [copy the build to tomcat/webapps]
archive artifacts
** [12-13 march]master -slave :
https://www.youtube.com/watch?v=8dZKT79DUfk
copy D:\jenkins\worksape\sample\target\*.war D:\tomcat\webapps

Find tomcat installation folder
delete hello-world (Note : tomacat server is shutdown then delete)

AIm : directly paste helloworld.war or all war file using jenkins in windows(install powershell plugin )




install java,git, maven in linux aws- server

What is master -slave concepts ?
master ? where your cloud install jenkins
workspace : eg :/roor/.jenkins
            eg :D:/Workspace/jenkins/

consider master in Window and slave is aws-ec2-linux(jenkins is not install)

Aim : all master job should be done in slave (/opt/devops)

Step 1 : Create AWS EC-2 as slave (get ip address, key) and install (java, maven,git) in slave
Step 2 : Create New Node(In Jenkins Node means Salve-server ) and Connect to Node to Jenkins  
** Step 1: Create AWS EC-2 as slave and install java,maven,git
In genreal we use shell scripts to install java,git and maven in slave node but for lecture we are manually isntall app.
*** INSTALL JAVA
#+BEGIN_SRC sh
# #####################################################
#   Java(1.8_0191,1.8_0131) installation in Linux# ####################################################
# dir to install software

sudo su-
mkdir sofwares

cd /opt/softwares


# install java- 8 (does not support higher version)
# updated for jdk 8u191
#wget --no-cookies --no-check-certificate --header "Cookie: gpw_e24=http%3a%2F%2Fwww.oracle.com%2Ftechnetwork%2Fjava%2Fjavase%2Fdownloads%2Fjdk8-downloads-2133151.html; oraclelicense=accept-securebackup-cookie;" "https://download.oracle.com/otn-pub/java/jdk/8u191-b12/2787e4a523244c269598db4e85c51e0c/jdk-8u191-linux-x64.tar.gz"

# updated for jdk 8u131
wget --no-cookies --no-check-certificate --header "Cookie: gpw_e24=http%3A%2F%2Fwww.oracle.com%2F; oraclelicense=accept-securebackup-cookie" "http://download.oracle.com/otn-pub/java/jdk/8u131-b11/d54c1d3a095b4ff2b6607d096fa80163/jdk-8u131-linux-x64.tar.gz"

# extract tar file
tar -xvzf jdk-8u131-linux-x64.tar.gz
rm -rf jdk-8u131-linux-x64.tar.gz

 # install java file # /software/jdk1.8.0_131
 vi ~/.bash_profile

# insert below text
# JAVA ENVIRONmENT VARIABLES
export JAVA_HOME=/opt/softwares/jdk1.8.0_131
export PATH=$PATH:/opt/softwares/jdk1.8.0_131/bin

# run bash
source ~/.bash_profile
java -version
#+END_SRC

*** INSTALL GIT AND maven
#+BEGIN_SRC sh
yum install git -y
#+END_SRC

*** INSTALL maven
#+BEGIN_SRC sh
cd /opt/softwares/

wget https://www-us.apache.org/dist/maven/maven-3/3.6.3/binaries/apache-maven-3.6.3-bin.tar.gz

vi ~/.bash_profile
#insert 
export M2_HOME=/opt/softwares/apache-maven-3.6.3
export PATH=$PATH:/opt/softwares/apache-maven-3.6.3/bin

# run bash_profile
source ~/.profile

mvn -version
#+END_SRC

** Step 2: Create and Connect Node(Slave-servet) to Jenkins(master- server)
- Step 1: Create a Slave :
  - Manage Jenkins > mange Node(Slave) 
     - New Node  
       - Node name : _<Slave-Server Name>_
       - Permanaent Agent : enable
       - OK
- Step 2: Configure Slave
  - executors : 1
  - remote root directory : _/opt/deploy/_  # dir in slave server
  - label            : _orange_
  - Launch method    : _Launch agents via SSH_
    - Host Name   : _18.188.173.210_ <AWS-Public Id>      
    - Credentials : _Jenkins_
       - Kind    : _SSH Username with private key_
       - Usernaem: _ec2-user_
       - Private key : enable
       - key : _<copy the key>_
    - Host Key Verification Strategy : _Non verification Strategy_
  - Node Progeries :
    - Toot Locations :
      - Name : _Java_
      - Home : _/opt/software/jdk1.8.0_131_
      - Name : _maven_
      - Home : _/opt/software/apache-maven-3.6.3/_
- BUG : if java, maven are not present then
  - Jenkins > mangae Jenkins > Global Tool Configuratoin > JDK (Add JDK) , maver(Add maven)
  - manage jenkins > mange nodes
- Step 3: Launch the Slave
  - Go to Slave Node and Lanunch the Node
** Step 3: Run job in Slave Node
- New Job or Job > Config >
  - General
    - Description
    - Discrad old build
    - GitHub project
    -
    -
    - Restrict where this project can be run
      - Lable : __<Give Slave Node Lable>___  




** TODO [14 march]Backup and Restoring point
- Step 1: Install "Backup or ThinBackup"
  - manage jenkins > manage plugins > install Backup OR ThinBackup
- Step 2: Configur  backup
  - manage jenkins > Backup Manager or (ThinBackup) >
    - Setup :
      - Background Configuration:
        - Backup dirctory : D:/paytm
        - Formate : zip/tar
        - File name template : backup_@date@.@extension@
          
- Step 3: Create a backup
  - manage jenkins > Backup Manager or (ThinBackup) >
    - Backup Hudson Configuration [ENABLE] # IT will CREATE BACKUP
      
- Step 4: Restore a backup
  - manage jenkins > Backup Manager or (ThinBackup) >
    - Resotre Hudson Configuration
      - Choose backup_file for backup
      
** install Jenkins  in  tomcat server (using war file)

- Install tomcat using above section on  Tomcat
- Download Jenkins war file on any version above 2
- Save war file in tomcat/webapp directory
- restart tomcat and load : local:8080/jenkins

├── bin  # executable file : start up and shutdown
├── conf # server.xml : change config 
|     └──server.xml # like port by default port is  :8080
├── log    
└── webapps 
      └── sbi.war  

** [19- march] Pass parameters in Jenkins
Ceate a script in path : /opt/softaware/scripts/test.sh
#+BEGIN_SRC sh
#!/bin/sh
echo "$1 is a good boy and $2 is a innocent guy"
#+END_SRC
*** Choices Parameter
-Step 1: Create a New job:
 - new item > free style  name: parameterijenkns
   - Genral
     - This project is parameterised :
       - Add Parameters:
         -      _Choice  Parameter_ : 
                  -               Name: param
                  -               Choices : mahesh 
                  -                         pawan
   - Build 
      -  Execute shell
          - command : sh /opt/softaware/scripts/test.sh $param


*** String Parameter
-Step 1: Create a New job:
 - new item > free style  name: parameterijenkns
   - Genral
     - This project is parameterised :
              -  String  Parameter : 
                 -                 Name          : param1
                 -                 Default Value : mahesh 
                                           
             -  String  Parameter : 
                -                  Name          : param2
                -                  Default Value : pawan 
   - Build 
     -   Execute shell
         -    command : sh /opt/softaware/scripts/test.sh $param1 @param2

* TODO Ansible :
*** [20 march] SSH-Key connection between master and all slave 
**** Prerequirement-I : Create a common user with root privillage and ssh-key base authentication

- Step to connect using SSH-Key:  
 - Create common user for all users (master and slave))
 - Give root privilege to common-user for both master and slave
 - Enable ssh-key based authentication( and restart sshd server)
#+BEGIN_SRC sh
#!/bin/bash
USER_NAME='ansible'    # $1
PASSWORD='karthik@123'   #$USER_NAME

##################################################################################
#   Create a common user 
##################################################################################
useradd ${USER_NAME}
echo ${PASSWORD} | passwd --stdin ${USER_NAME}
passwd -e ${USER_NAME}

if [[ "${?}" -ne 0 ]]   # # if [ "#?" !=0]
then
  echo "Password create sucessfull"
else
      exit 1
fi
#check if user is created or not 
# cat/etc/passwd
##################################################################################
# Give root privilege
##################################################################################
if grep -q "${USER_NAME}" "/etc/sudoers"    #[[ "${?}" -ne 0 ]]
then
  echo "Alread exiting "
else
  echo "Need to add to sudoers"
  echo -e "## Allow ${USER_NAME} to run any commands anywhere\n${USER_NAME}\tALL=(ALL)\tNOPASSWD: ALL" >> /etc/sudoers
  # sed -i 's/root    ALL=(ALL)       ALL/root    ALL=(ALL)       ALL \n${USER_NAME}\tALL=(ALL)/g' /etc/sudoers
fi
grep "$USER_NAME" "/etc/sudoers"
##################################################################################
# Enable ssh-key based authentication
##################################################################################
sed -i 's/^PasswordAuthentication no/#PasswordAuthentication no/' /etc/ssh/sshd_config
sed -i 's/#PasswordAuthentication yes/PasswordAuthentication yes/' /etc/ssh/sshd_config
grep 'PasswordAuthentication' /etc/ssh/sshd_config
service sshd restart
#+END_SRC

**** Prerequirement-II: Generate ssh-key in master and share it with all slave  

 - Create ssh-key in master 
#+BEGIN_SRC sh
ssh-keygen   #check key "id_ras.pub" ls -latr /home/ansible/.ssh
ssh-copy-id devops@slave_ip
#+END_SRC

 - check ssh without password
#+BEGIN_SRC sh
ssh <user-name>@ip
# show-key : cat /home/<user-name>/devops/.ssh/authorizzed_keys
exit() # to exist 
#NOTE: we can connect from master to slave but not from slave to master
#+END_SRC
*** [21 march] Installation

#+BEGIN_SRC sh
wget http://dl.fedoraproject.org/pub/epel/epel-release-latest-7.noarch.rpm
rpm -ivh epel-release-latest-7.noarch.rpm
yum repolist
#yum install epel-release
yum update
yum install git python openssl ansible -y
ansible --version

#+END_SRC

*** [21 march ] Inventory Enable and Example
#+BEGIN_SRC sh
# Enable /etc/ansible/host by un-commenting <inventory> in ansible.cfg file
#vi /etc/ansible/ansible.cfg
#inventory = /etc/ansible/hosts




# /etc/ansible/host           # contain all information slave host in yaml file

#EXAmPLE : Ansible has inventory files where host info are stored and used.
# inventory = /etc/ansible/host
#vi /etc/ansible/hosts   # System given examples

#[web]
# 192.147.58.9
#[app]
# 192.147.59.7
#[dbserevr]
# 192.34.5.6
# using host file we create cluster in order to run cmd on cluster we 

#+END_SRC
*** [21 march ]Ad-hoc commands
You could execute a quick one-liner cmd in ansible with-out writing playbook
#+BEGIN_SRC sh
ansible [groupname] -a "command"      # a : attributes

# Ex:
ansible test -a "ls -l /opt"
ansible test -a "cat /etc/passwd"
ansible servername -a "touch /opt/test123" -s
ansible servername -a "ls -l /opt"
ansible all -a "yum remove httpd -y" -s
ansible test -s -a "useradd batch31"
ansible all -a "ls -l /opt"



# module
ansible web -a "service httpd status" --become 
ansible web -m yum -a "name=httpd state=stopped" --become
ansible web -m yum -a "name=httpd state=absent"# uninstall httpd(apache)
ansible web -a"service httpd status" --become
#

ansible web -m copy -a "src=/etc/hosts dest=/tmp/hosts"
# change file permission and ownership
ansible web -m file -a "dest=/srv/foo/b.txt mode=600 owner=meheen group=maheen"
# #############################################
#  Create users
# #############################################
# Encrpt password :https://www.radb.net/crypt_calculator 
ansible all -m user -a"name=test password=cFl0NSByhlhXc" --become
ansible all -a"cat /etc/passwd" --become # check user is created

# #########################################
#  Custom inventory file
# #########################################
#path of inventory file path: /opt/hosts
ansible -i /opt/hosts app -a "ls -latr /opt"
ansible -i /opt/hosts app -a "ping"
ansible -i /opt/host -m yum -a "name=git state=latest"#
ansible -i /opt/host -m yum -a "name=tomcat state=latest"#

#+END_SRC

ansible help cmd
#+BEGIN_SRC sh
ansible-doc -l | wc
# ansible-doc -s module-name
ansible-doc -s yum
#+END_SRC
*** modules : Adhoc cmd are converted in module for simple and easy use
There different types of module  [[https://docs.ansible.com/ansible/latest/user_guide/modules_intro.html][Introduction to module]]

Modules (also referred to as “task plugins” or “library plugins”) are discrete units of code that can be used from the command line or in a playbook task. Ansible executes each module, usually on the remote target node, and collects return values.
#+BEGIN_SRC sh
# 
ansible [pattern] -m [module-name] -a "[module-option]"
# pattern : group or cluster in inventory file

# -a      : attributes of module
# -m      : module
# $ansible-doc -l |wc
#$ ansible-doc yum
#$ ansible-doc yum 
# Example: # state=latest or present, absent(remove install)
# ansible 
ansible web -m yum -a "name=httpd state=latest"# ################################
#                yml file
# ##############################
- name: install latest version of Apache
  yum:
    name: httpd
    state: latest

#############################################
#$ ansible-doc service   
# Example: state : started, stopped,restarted
ansible web -m service -a "name=httpd state=started" --become # install apache server

#                yml file
- name: start service hhtpd
  service:
    name: httpd
    state: started
##################################

ansible web -a "service httpd status" --become 
ansible web -m yum -a "name=httpd state=stopped" --become
#
ansible web -m yum -a "name=httpd state=absent"# uninstall httpd(apache)

# #############################################
#  Create users
# #############################################
# Encrpt password :https://www.radb.net/crypt_calculator 
ansible all -m user -a"name=test password=cFl0NSByhlhXc" --become
ansible all -a"cat /etc/passwd" --become # check user is created

# #########################################
#  Custom inventory file
##########################################
#path of inventory file path: /opt/hosts
ansible -i /opt/hosts app -a "ls -latr /opt"
ansible -i /opt/hosts app -a "ping"
ansible -i /opt/host -m yum -a "name=git state=latest"#
ansible -i /opt/host -m yum -a "name=tomcat state=latest"#
#+END_SRC
***** Example
#+BEGIN_SRC sh
ansible webserver -m yum -a "name=git state=latest"

ansible all -m yum -a "name=httpd state=latest"

ansible test -m ping

ansible all -m copy -a "src=/opt/docker-compose.yaml dest=/opt" -s

ansible appserver -m yum -s -a "name=httpd state=present"

ansible all -m yum -s -a "name=httpd state=absent"

ansible all -m yum -s -a "name=git state=latest"

ansible test -m user -s -a "name=batch31"

ansible test -m user -s -a "name=batch31 state=absent"

ansible all -m service -s -a "name=httpd state=started"


#+END_SRC
**** Playbook(.yaml)
module: to run single tast or one time task

To run multiple task , run repeted task

https://www.softwaretestinghelp.com/ansible-playbooks-ansible-vaults/

to get yaml formate example:
yml consist of ( hosts,variable,tasks) and task is array 

variable: optional 
task contain : module and attributes informations

#+BEGIN_SRC sh
ansible-doc git
#+END_SRC

***** Command type playbook
#+BEGIN_SRC sh
#cat sample.yml
##################################
---
- hosts: app
  become: true
  tasks:
  - name: install python
    yum:
      name: python
      state: latest
##########################################
ansible-playbook sample.yml --syntax-check
ansible-playbook sample.yml --list-hosts
ansible-playbook sample.yml # to run yml file


#cat useradd.yml
##################################
---
- hosts: app
  become: true
  tasks:
  - name: creating user
    yum:
      name: statish
      state: /pL2AYR6csdTI
ansible-playbook useradd.yml --syntax-check
ansible-playbook useradd.yml 
ansible app -a "cat /etc/passwrd" --become
##########################################
#cat httpd_installNrun.yml
##################################
---
- hosts: app
  become: true
  tasks:
  - name: install httpd
     yum:
       name: httpd
       state: latest
  - name:start service
     service:
        name: httpd
        state: started
ansible-playbook httpd_installNrun.yml --syntax-check
ansible-playbook httpd_installNrun.yml
##########################################
#cat create_file.yml
##################################
---
- hosts: app
  tasks:
  - name: create file
     file:
      path: /opt/vbs
       state: touch
ansible-playbook create_file.yml --syntax-check
ansible-playbook create_file.yml

#+END_SRC
*** modules
- modules
  - System (User, Group, Hostname, Iptables, Lvg, Lvol, make, mount,ping, Timezone, Systemd, Service)
  - Commands (Command, Expect , RAW, Script, Shell)
  - Files (Acl, Archive, File, Find, Lineinfile, Replace, Stat, Template, Unarchive)
  - Database(mongodb,mssql,mysql, Postgresql, Proxysql, vertica)
  - Cloud (Amazon, Atomic, Azure, Centrylink,Cloudscale,Cloudstack,Digital Ocean, Docker,Google, Linode, Openstack, Rackspace, Smartos, Softlayer, Vmware)
  - Windows (In windows environment)
  - git ()
  - .....
  - 
  - shell
  - command
  - script
#+BEGIN_SRC sh
-
 name: Play 1
 hosts: localhost
 tasks:
 - name: Execute command ‘date’
   command: date

 - name: Display resolv.conf contents
   command: cat /etc/resolv.conf

 - name: Display resolv.conf contents
   command: cat resolv.conf chdir=/etc

 - name: Display resolv.conf contents
   command: mkdir /folder creates=/folder

 - name: Copy file from source to destination
   copy: src=/source_file dest=/destination

 - name: Run a script on remote server
   script: /some/local/script.sh -arg1 -arg2
# Services : Started,Stopped,Resatared
 - name: Start the database service
   service: name=postgresql state=started

 - name: Start the httpd service
   service: name=httpd state=started

 - name: Start the nginx service
   service:
     name: nginx
     state: started
 - name: Start the database service
   service:
     name: postgresql
     state: started
# Lineinfile
# Search for a line in a file and replace it or add it if it doesn’t exist.
- lineinfile:
    path: /etc/resolv.conf
    line: 'nameserver 10.1.250.10'
# Ping
  - name: Ping test
    ping:

#+END_SRC
*** [24 march] when should we use ad-hoc and playbook
For ad-hoc to run commands which are used rarely
      For runing single instruction

For playbook:
     For running set of/complex insrtuction 
     For createing same enviroment 
#+BEGIN_SRC sh
ansible-doc -s yum
#+END_SRC
*** [24 march] Palybook service (state: reloaded, restarted, started, stopped)
#+BEGIN_SRC sh
 - name: start serveice
   service:
      name: httpd
      state: started # reloaded, restarted, started, stopped,abscent

#+END_SRC
*** Palybook copy-module
#+BEGIN_SRC sh
#$ansible-doc copy
- name: Copy file with owner and permissions
  copy:
    src: /srv/myfiles/foo.conf
    dest: /etc/foo.conf
- name: Copy a new "sudoers" file into place, after passing validation with visudo
  copy:
    src: /mine/sudoers
    dest: /etc/sudoers
    validate: /usr/sbin/visudo -csf %s

#+END_SRC

#+BEGIN_SRC sh
cd /opt
#vi copy_pb.yml
---
- hosts: web
  task:
  - name: copy file
    copy:
      src: /opt/sbi.war
      dest: /tmp/sbi.war
...
# #########################333
#   Using SRC
# #########################3
- hosts: web
  become:true
  vars:
    dst_path: /opt
    src_path: /opt/icici.war
  task:
  - name: copy file
    copy:
      src: "{{src_path}}"
      dest: "{{dst_path}}"
...
#+END_SRC
*** Playbook for create a user 
#+BEGIN_SRC sh
ansible-doc user # search for playbook example
#+END_SRC

#+BEGIN_SRC sh
- name: Add user 
  user:
    name: johnd
    comment: John Doe
    uid : 1040
    group: admin

ansible all -m user -a"name=test password=cFl0NSByhlhXc" --become
# passing password in playbook is not best practice
# In generall we pass encripted password 
# google search encrypted password
# replace password with encrypted

#+END_SRC
*** (yml file ) Playbook create, run , check 
- TOP LEVELS
 - HOST SECTION
 - VARABLE SECTION
 - TASKS  SECTION

For interview please pratice using online examples :
https://www.softwaretestinghelp.com/ansible-playbooks-ansible-vaults/
#+BEGIN_SRC sh
--- 
- 
  become: true
  hosts: azure
  tasks: 
    - 
      name: "install httpd"
      yum: 
        name: httpd
        state: latest
    - 
      name: "start serveice"
      service: 
        name: httpd
        state: started
    - 
      file: 
        mode: "0777"
        path: /var/www
        state: directory
      name: "Create a directory if it does not exist"
    - 
      copy: 
        dest: /var/www/html/index.html
        src: /opt/scripts/index.html
      name: "copy module"
    - 
      name: "restart serveice"
      service: 
        name: httpd
        state: resarted
# ansible-playbook ansible_pb1.yml --syntax-check
#+END_SRC

#+BEGIN_SRC sh
  - name: copy module
    copy:
     src: /opt/index.html
     dest: /var/www/html/index.html
    notify:
    - restart apache
  handlers:
    - name: restart apache
      service:
       name: httpd
       state: restarted
#+END_SRC
**** Run yml file
#+BEGIN_SRC sh
ls
# python install

# chek sytanx
ansible-playbook pythonisntall.yml --syntax-check
ansible-playbook pythonisntall.yml --list-host
ansible-playbook pythonisntall.yml # to run  playbook
#+END_SRC
*** [24 march] Playbook for file-module 
Basic yml to be remember during interviews
https://www.softwaretestinghelp.com/ansible-playbooks-ansible-vaults/

#+BEGIN_SRC sh
# $ansible-doc file # go to example

- name: Create a directory if it does not exist
  file:
    path: /etc/some_directory
    state: directory
    mode: '0755'


- name: Remove file (delete file)
  file:
    path: /etc/foo.txt
    state: absent

- name: Recursively remove directory
  file:
    path: /etc/foo
    state: absent


- name: Change file ownership, group and permissions
  file:
    path: /etc/foo.conf
    owner: foo
    group: foo
    mode: '0644'

- name: Change file ownership, group and permissions
  file:
    path: /etc/foo.conf
    owner: foo
    group: foo
    mode: '0644'

- name: Change file ownership, group and permissions
  file:
    path: /etc/foo.conf
    owner: foo
    group: foo
    mode: '0644'

#+END_SRC

#+BEGIN_SRC sh
cd /opt
#vi dry.yml
---
- hosts: web
  become: true
  task:
  - name: create dir
    file:
      path: /opt/test_dir
      state: directory
      mode: '0755'
  - name: change permission and ownership
    file:
      path: /opt/test_dir
      owner: ansible
      group: ansible
      mode: '0777'
  - name: create touch
    file:
      path: /opt/test.txt
      state: touch
      mode: '0755'
  - name: create multiple touch
    file:
      path: "{{item}}"
      state: touch
      mode: '0755'
    with_item:
      - "/opt/satishP"
      - "/opt/satishT"
      - "/opt/rajit"
      - "/opt/karthik"

  - name: Remove file (delete file)
    file:
      path: /opt/test.txt
      state: absent
  - name: Recursively remove directory
    file:
      path: /opt/etc/foo
      state: absent
    
...
#+END_SRC
*** Varaible
#+BEGIN_SRC sh
---
 name: Add DNS server to resolv.conf
 hosts: localhost
 vars:
   dns_server: 10.1.250.10
 tasks:
 - lineinfile:
     path: /etc/resolv.conf
     line: 'nameserver {{dns_server }}’
#+END_SRC

#+BEGIN_SRC sh
---
- hosts: all
  become: ture
  vars: 
      dest_path: /opt
      src_path: /opt/icici.war
  tasks:
  - name: copy
    copy:
        src:"{{src_path}}"
        dest:"{{dest_path}}" 
...
#+END_SRC

#+BEGIN_SRC sh
- 
  name: Set Firewall Configurations
  hosts: web
  var:
    http_port: 8081
    snmp_port: 161-162
    inter_ip_range: 192.0.2.0
  tasks:
  - firewalld:
      service: https
      permanent: true
      state: enabled

  - firewalld:
      port: ‘{{ http_port }}’/tcp
      permanent: true
      state: disabled
  - firewalld:
      port: ‘{{snmp_port}}’/udp
      permanent: true
      state: disabled
  - firewalld: 
      source: ‘{{ inter_ip_range}}’/24
      Zone: internal
      state: enabled
#+END_SRC
*** [24 march] Playbook Java installation:
**** varibale
 SOURCE: https://gist.github.com/andershedstrom/7c7d0bb5b9450c54a907
#+BEGIN_SRC sh
---
- hosts: web
  become: true
  vars:
   download_url: http://download.oracle.com/otn-pub/java/jdk/8u131-b11/d54c1d3a095b4ff2b6607d096fa80163/jdk-8u131-linux-x64.tar.gz
   dst_path: /opt/software
  tasks:
  - name: Create a directory if it does not exist
      file:
        path: "{{dst_path}}"
        state: directory
        mode: '0777'

  - name: Download JDK tar file
    command: "wget --no-check-certificate --no-cookies --header 'Cookie: oraclelicense=accept-securebackup-cookie' {{download_url}} "
    args:
      chdir: "{{dst_path}}"

  - name: Extract tar file
    command: "tar -xvzf jdk-8u131-linux-x64.tar.gz;rm -rf jdk-8u131-linux-x64.tar.gz"

  - name: Set JAVA PATH
      shell: echo "# JAVA ENVIRONmENT VARIABLES" >> ~/.bash_profile; echo "export JAVA_HOME=/opt/softwares/jdk1.8.0_131">> ~/.bash_profile; echo "export PATH=\$PATH:/opt/softwares/jdk1.8.0_131/bin">> ~/.bash_profile

  - name: restart bash and check version
      shell:   - name: Set JAVA PATH
      shell: source ~/.bash_profile; java -version
#+END_SRC
*** Looping
#+BEGIN_SRC sh
-
  name: Create users
  hosts: localhost
  tasks:
  - user: name= ‘{{ item }}’
    loop:
      - joe
      - george
      - ravi
      - mani
      - kiran
      - jazlan
      - emaan
      - mazin
      - izaan
      - mike
      - menaal
      - shoeb
      - rani
#+END_SRC

#+BEGIN_SRC sh
- 
  name: Create users
  hosts: localhost
  tasks:
  - user: 
      name= ‘{{item.name}}’  
      state= present
      uid= '{{ item.uid}}’

    loop:
     - name: joe
       uid: 1010
     - name: george
       uid: 1010 
     - name :ravi
       uid: 1012
     - name:mani
       uid: 1013
     - name:kiran
       uid: 1014
     - name:jazlan
       uid: 1015
     - name:emaan
       uid: 1016
     - name:mazin
       uid: 1017
     - name:izaan 
     - name:kiran
       uid: 1018
     - name:mike 
#+END_SRC
**** With_item
#+BEGIN_SRC sh
- name: Create users 
  hosts: localhost 
  task: 
  - user: name='{{ item }}'
    state: present 
    with_item: 
    - joe 
    - george 
    - ravi 
    - mani
#+END_SRC


**** With_file
#+BEGIN_SRC sh
- name: Create users 
  hosts: localhost 
  task: 
  - debug: var=item
    with_file: 
    - "/etc/hosts"
    - "/etc/resolve.conf"
    - "/etc/ntp.conf"
#+END_SRC
**** With url
#+BEGIN_SRC sh
- name: get multiple urls
  hosts: localhost 
  task: 
  - debug: var=item
    with_url: 
    - "https://site1.com/get-servers"
    - "https://site2.com/get-servers"
    - "https://site3.com/get-servers"
    - "https://site4.com/get-servers"
#+END_SRC
**** With mongodb:
#+BEGIN_SRC sh
- name: get multiple mongodbs
  hosts: localhost 
  task: 
  - debug: msg "DB={{item.database}} PID={{item.pid}}"
    with_url: 
    - database: dev
      connection_string : "mongodb://dev.mongo/"
    - database: dev
      connection_string : "mongodb://prod.mongo/"

#+END_SRC
**** With_*
#+BEGIN_QUOTE
with_items
with_file
with_url
with_mongodb
with_dict
with_etcd
with_env
with_filetree
With_ini
With_inventory_hostnames
With_k8s
With_manifold
With_nested
With_nios
With_openshift
With_password
With_pipe
With_rabbitmq
With_redis
With_sequence
With_skydive
With_subelements
With_template
With_together
With_varnames
#+END_QUOTE
*** Condtions
#+BEGIN_SRC sh
---
- name: Install NGINX
  hosts: all
  tasks:
  - name: Install NGINX on Debian
      apt:
        name: nginx
        state: present
      when: ansible_os_family == “Debian” and
            ansible_distribution_version == “16.04”
 - name: Install NGINX on Redhat
     yum:
       name: nginx
       state: present
     when: ansible_os_family == “RedHat” or
           ansible_os_family == "SUSE"
#+END_SRC
*** Condtionals in Loop
*** Condtionals & Register
*** [25 march] Roles
Ansible: assigne a role to server or host : like (mysql, gameserver: nginx,)
The same work can be done by palybook why we use role ?

This are task which are comman used by all dev, or with in organiziatoin.,,,etc
*** Find Roles
ansible-galaxy :web UI
$ansible-galaxy search mysql
*** Use Roles
#+BEGIN_SRC sh
ansible-glaxy install geerlingguy.msql
#+END_SRC
*** List Roles
#+BEGIN_SRC sh
ansible-galaxy init mysql # 
# How to use mysql in my playbook 
# move role to comman dir where ansible can find the location (/etc/ansible/roles)



#+END_SRC

*** Patter 
#+BEGIN_SRC sh
- 
 name: Play1
 hosts : localhost, # Host*, *.company.com # Host1,Host2,Host3,
 tasks:
 - name: Copy file with owner and permissions
   copy:
     src: /srv/myfiles/foo.conf
     dest: /etc/foo.conf
 - name: Copy a new "sudoers" file into place, after passing validation with visudo
  copy:
    src: /mine/sudoers
    dest: /etc/sudoers

#+END_SRC
*** Dynamic Inventory:
#+BEGIN_SRC sh
ansible-playbook -i inventory.txt palybook.yml #static inventory
ansible-playbook -i inventory.py playbook.yml # dynamic inventory
#+END_SRC
*** Custom modules:
https://docs.ansible.com/ansible/2.3/dev_guide/developing_modules_general.html
*** [25 march]Jinja Template : 
Insted of copy we use Jinja template which move the only contant of file
#+BEGIN_SRC sh
---
- hosts: azure
  become: true
  vars:
    src_path: /opt/devops.j2
    dst_path: /var/www/html/index.html
  tasks:
  - name: install httpd
    yum:
      name: httpd
      state: latest
  - name: start serveice
    service:
       name: httpd
       state: started
  - name: copy module
    template:
     src: "{{ src_path }}"
     dest: "{{ dst_path }}"
    notify:
    - restart apache
  handlers:
    - name: restart apache
      service:
       name: httpd
       state: restarted
#+END_SRC

#+BEGIN_SRC html
  <html>
  <header><title>This is title</title></header>
  <body>
  Hello CARONA world CUP 2020 fwefwefgwe
  gwrgrgrgrgrgrgrg
  rgr
  greg
  reg
  rger
  grg
  </body>
  </html>

#+END_SRC
* Ansible(Advance) 
*** Role
*** Asynchronous Actions
**** Why Asynchronous
Time when we need to execute a long task that excceds the ssh-time out
Insted of extending we  make a check on it later time

To run mulitpule processes at once and check on it later

To run  one or more process and not check it staus
#+BEGIN_SRC sh
- name: Deploy Web Application
  hosts: web
  tasks:
  - command: /opt/monitor_webapp.py
    async: 360 # How long to run ? 
    poll: 60   # How frequently to check default 10 sec?
    register: webapp_result
               # poll: 0 , Not waiting check and go to other task


  - command: /opt/monitor_database.py
    async: 360 # How long to run ? 
    poll: 60   # How frequently to check default 10 sec?
    register: database_result
               # poll: 0 , Not waiting check and go to other task

  - name: Check status of tasks
    async_status: jid={{webapp_result.ansible_job_id}}
    register: job_result.finished
    retries: 30

# Not all module support async
#+END_SRC
*** Strategy
How playbook is executed in ansible
#+BEGIN_SRC sh
-
 name: Deploy Web Applications
 strategy: free
# Batch 
# serial:3(linear for 1st 3 server) later are free strategy
 hosts: server1
 tasks:
  - name: Install dependencies
     ########################
  - name: Install mySQL databases
     ########################
  - name: Start mysql service
     ########################
  - name: Install Python Flask dependencies
     ########################
  - name: Run web-server 
     ########################
#+END_SRC
*** Forks
How many server can it talk to at a time ?
If we have 100 servers ? will servers run at atime ?
How many servers will ansible take at atime ?

Ansible uses parallel process called frok  communicate with host 
default ansible talk 5 servers at atime.
*** Error Handling
In strategy topic we see linear, free, batch

If one server there is error <like  mysql server> then ansible take error out of list and continue the playbook

If we want to stop execution if there is an error in execution use *any_errors_fatal*
**** ignore_errors: 
consider we want to send a mail at end of task telling <Web Server Deployed>
How ever stmp server is not stable so we don't want to give error because of it and stop, FOR this kind of thinks we want to ignore the error
#+BEGIN_SRC sh
- mail:
    to: devops@corp.com
    subject: Server Deployed!
    body: Web Server Deployed
  ignore_errors: yes
#+END_SRC
**** failed_when:
We want to check the *Error log* and see if there is an error in it or not then we want to fail the if error as occured
#+BEGIN_SRC sh
- command: cat /var/log/server.log
  register: command_output
  failed_when: " 'ERROR' in command_output.stdout"
#+END_SRC

*** Jinja 2 Templating(Filters)
What is Templating : process of dynamic content :
#+BEGIN_SRC yml
- 
 name: Test Template Playbook
 hosts: localhost
 vars:
   my_name: karthik
 tasks:
  - debug:
       msg: "my name is {{my_name}}"

#+END_SRC

**** String manipualtion
#+BEGIN_QUOTE
The name is {{my_name}}=> The name is karthik
The name is {{my_name | upper}}=> The name is KARTHIK
The name is {{my_name | lower}}=> The name is karthik
The name is {{my_name | title}}=> The name is Karthik
The name is {{my_name | repalce("karthik","Sai Teja")}}=> The name is Sai Teja
The name is {{my_name | default("James")}} {{my_name}}=> The name is James Karthik
#+END_QUOTE
**** List and Set based filter
#+BEGIN_SRC yml
{{ [1,2,3] | min }}                >> 1
{{ [1,2,3] | max }}                >> 3
{{ [1,2,3,2] |unique }}                >> 1,2,3
{{ [1,2,3,4] |union([4,5])}}                >> 1,2,3,4,5
{{ [1,2,3,4] | interset([4,5]}}                >> 4
{{ 100 | random }}                >> Random number
{{ ["The", "name", "is","Bond"] | join (" ")}}                >> The name is Bond
#+END_SRC
**** File based Filter
#+BEGIN_SRC yml
{{ "/etc/hosts" | basename}}            >> hosts
{{"c"\windows\hosts" | win_basedname }}            >> hosts
{{ "c:\windows\hosts" | win_splitdrive }}            >> ["C:","\windows\hosts"]
{{ "c:\windows\hosts" | win_splitdrive| first }}            >> "C:"
{{ "c:\windows\hosts" | win_splitdrive| last }}            >> "\windows\hosts"

#+END_SRC
**** more Info about Jinja2 Filters 
GOogle Search: jinja2 List of Builtin Filters
*** Lookups
If we store hosts and password in csv file we can read the password we can use lookup plugin
#+BEGIN_SRC sh
#$ cat credentials.csv
#Hostname, Password
#Target1, PasswOrd1
#Target2, PasswOrd2


{{lockup('csvfile', 'target1 file=/tmp/credentials.csv delimiter=,')}} >> PasswOrd1
#+END_SRC

There are other type of Lookups like INI,DNS,mongodb
Source : Web : Ansible Documentation > Playbooks:Special Topic > Lookups 
*** Vault
We are storing password in host or inventory file 
Ansible vault help to encript the host or inventory file
#+BEGIN_SRC sh
# To encrypth inventory file
ansible-vault encrypt inventory.txt
# $ask for password


# run encrypted inventory file
ansible-playbook test.yml -i inventory.txt -ask-vault-pass

# pass file(vault_pass) containing password
ansible-playbook test.yml -i inventory.txt -valt-password-file ~./vault_pass

# pass script(vault_pass.py) containing password
ansible-playbook test.yml -i inventory.txt -valt-password-file ~./vault_pass.py

# view contant of encrpyted file 
ansible-vault view inventory.txt

# To create an encrypted file 
ansible-vault create inventory.txt

#+END_SRC
*** Dynamic Inventory

#+BEGIN_SRC python
#!/usr/bin/env python

import json

def get_inventory_data():
    return {
        'databases': {
            'hosts': [ip_address],
            'vars': {
               "ansible_ssh_pass":"PasswOrd",
               "ansible_ssh_host":"192.168.1.1"
            }
        }
        'web': {
            'hosts': ["web_servers"],
             'vars' : {
               "ansible_ssh_pass":"PasswOrd2",
               "ansible_ssh_host":"192.168.1.2"  
                }
            }
        }
    
if __name__ == '__main__':
    inventory_data = get_inventory_data()
    print(json.dumps(inventory_data))

#+END_SRC
*** Custom modules
*** Plugins
** Example
#+BEGIN_SRC sh
---
- name: Play 1
  hosts: test
  become: yes
  tasks:
      - name: Installing the git package
      - yum: name=git state=present

2))
---
---
- hosts: all
  become: yes
  tasks:
      - name: copying the files from server to client
      - copy: src=/etc/passwd dest=/opt

3))
----
---
- hosts: all
  become: yes
  tasks:
      - name: Installing multiple packages
      - yum: state=present name={{ item }}
   with_items:
- git
- wget
- httpd
- tar
- vim
4))

---
- hosts: all
become: yes
tasks:
- name: Installing jenkins
yum:
name: /opt/jenkins-2.129-1.1.noarch.rpm
state: present
- service:
name=jenkins state=started

5))
----
---
- hosts: all
become: yes
tasks:
- name: Sample playbooks
yum: name=httpd state=present
- name: starting httpd services
service: name=httpd state=started




- hosts: appserver

remote_user: ansible1

become: true

tasks:
- name: Install Apache Webserver
yum: pkg=httpd state=latest
- name: restart apache
service: name=httpd state=restarted

#+END_SRC
* [28 march] Docker
** Onframe and Cloud
Private Data Center : 
IRCTC OR BSNL private data centers
Disatvangaes:
Cons: If you want a server (assign diskpace, dependencecy, users creation, check network) minimum 3-4 days

Simillary to lanch a server we may need 3-4 days


If there is Suddenly increase  user ? How can we increase the user in short time ?
Example: irctc 10-12 am tatkal ticket(AC and SC)
Q) How increse servers dynamically based on online-users ?
A) Containerizaztion

In docker any software is called a image based on one image we can create many servers

Onframe uses a Virtual machine,Vm-ware,Oracle virtual machine

Pro:
protable(Docker hub)
scalable





** Installation Docker and cmds
Install docker
#+BEGIN_SRC sh
yum install docker -y
# Download image from docker hub
# satish: images thetheis
# create a account dockerhub

service docker status
service docker start
service docker status

# list of images in your docker 
docker images
docker search centos
docker pull centos

docker run -it --name sathish-centos centos # creatre and run in background

#
# to show the running container
#
docker ps #or docker container ls
# CONTAINER ID        IMAGE               COMMAND                  CREATED              STATUS              PORTS                  NAMES
# d2bf3ff05b9b        nginx               "nginx -g 'daemon of…"   19 seconds ago       Up 17 seconds       80/tcp                 my_nginX

# docker ps -a # to show the running and stoped containers
# Enter inside container
docker exec -it d2bf3ff05b9b /bin/bash   # Enter inside the container
 
docker stop d2bf3ff05b9b # stop container
docker rm d2bf3ff05b9b # to remove the container
#+END_SRC    

Port Forwording ,Volumes....etc

** Create/pull image and Create container 
#+BEGIN_SRC sh
# To check images
docker images

# Create Image of centos7 or ubuntu
docker pull ubuntu
docker pull centos:7

# create/run a container
docker run -itd --name sathis-dev centos:7

# check running containers  
docker ps

# go inside container
docker exec -it <container-id> /bin/bash

# delete container
docker stop <container-id>/<container-name>
docker rm  <container-id>/<container-name>

# delete image
docker rmi centos:7
#+END_SRC

* [30 march] Port Forwording, Volume and Bind mount
Which application has port ?
tomcat 8080
nginx
jenkins
httpd: 80

port forwding:

#+BEGIN_SRC sh
docker pull tomcat:9  
docker images #or
docker image ls
docker run -itd --name tomcat-dev -p 8081:8080 tomcat:9
docker ps
# CONTAINER ID        IMAGE               COMMAND             CREATED             STATUS              PORTS                    NAMES
# 5289647926e3        tomcat:9            "catalina.sh run"   10 seconds ago      Up 5 seconds        0.0.0.0:8081->8080/tcp   tomcat-dev

# open ip:8081  # we are acessing from 8081 port outside container to inside 
docker run -itd --name tomcat-dev -p 8081:8080 nginx

#+END_SRC
** Volume and Bind mount 
local(host) linux and container dir are synchronized

local and container are have shared space
#+BEGIN_SRC sh
cd /opt
mkdir devops
cd devops
touch sbi.war icic.jar
# docker run -itd -v <local-path(host OS)> : <container-path> <image-name> # Bind mounts
docker run -itd -v /opt/devops: /opt/sathish centos # Bind mounts
docker run -itd --name sathish-jenkins -p 8083:8080 jenkins

#+END_SRC
* [1st April] Database mysql
#+BEGIN_SRC sh
docker run -itd --name sathish_mydb -e MYSQL_ROOT_PASSWORD=12345 mysql:5
docker exec -it sathish_mydb  /bin/bash
$# mysql -u root -p # inside the docker 
mysql> # inside mysql 
show databases;
use name
select * from emp;
exit
exit
docker system prune -a # To delete unsed images,containers, networks, volumes
#+END_SRC

** Docker File
#+BEGIN_SRC sh
# FROM # which image should be take
FROM ubuntu

MAINTAINER "sathish-devops"
LABEL CEO ="apple"

# RUN # run linux cmd
RUN apt-get update
RUN apt-get install git -y
#RUN yum install java-1.8.0-openjdk -y
# COPY # copy from  local to container
COPY /opt/sofware/jenkins.war /tmp

ADD https://updates.jenkins-ci.org/download/war/2.229/jenkins.war /tmp
# ADD  
   #1.To copy local to container, and 
   #2.copy from remote( internet url) to container

EXPOSE 8080 # port should be enabled
WORKDIR /opt/dev # change dirctory

# cmd :
  # 1. msg will be executed while container is executed
  # 2. To over-ride the cmd
  # 3. To over-ride msg: 
    # eg: docker run -it sat-dev echo "hi sathish"

CMD ["git", "version"]    # show result run container in non-detached  mode
# docker run -it <image-name>
CMD ["data"] # Over-ride the  last cmd and execute last cmd


ENTRYPOINT
#+END_SRC

** Docker with Jenkins 
#+BEGIN_SRC sh
FROM centos:7
RUN yum install java-1.8.0-openjdk -y
ADD https://updates.jenkins-ci.org/download/war/2.229/jenkins.war /tmp
#+END_SRC

#+BEGIN_SRC sh
docker build -t sat-dev .

#+END_SRC
* [3rd April] Docker File
Docker file is look like shell but it is not
** Edit Docker File 
#+BEGIN_SRC sh
  # Docker-formate not shell script
  # 1
  FROM debian:jessie 
  FROM centos
  # 2
  MAINTAINER "sathish" 
 
  LABEL CEO ="apple"
  LABEL DRT ="stephen"


  # 3
  RUN mkdir /opt/demo
  RUN mkdir /opt/demo && \
      touch /opt/devops && \
      yum install git -y \
      yum update ;

  RUN mkdir /opt/demo && touch /opt/devops && yum install git -y    yum update ;

  RUN # INSTALL packages or unzip....etc
  #  &&    make all cmd into one layer
  #  &&      

  # 4
  WORDIR /opt  # change dir
  RUN mkdir aws
  ADD www.tomcat.tar /opt
  # 6
  # COPY SRC DEST
  COPY /opt/sample.war /tmp

  # 7
  ADD 
  # 1) Copy a file from local linux to container
  # 2) it download from internet 
  ADD www.tomcat.tar /opt # download tocat.tar to /opt

  # 8
  ENV    # SET ENVIROmENT Varible 
  # 
  # # set environment in linux
  #
  #export JAVA_HOME=/usr/lib/jvm/default-java
  #export M2_HOME=/opt/maven
  #export MAVEN_HOME=/opt/maven
  #export PATH=${M2_HOME}/bin:${PATH}
  #
  # SET ENVIROmENT VARIABLE IN DOCKER FILE
  #
  ENV JAVA_HOME /opt/java-1.8.0/java
  ENV PATH /opt/java-1.8.0/java/bin
  RUN export JAVA_HOME
  RUN export PATH

  ENV NGINX_VERSIN 1.11.10-1~jessie

  # 9) 
  EXPOSE 8080  # Enable port 
  # 10

  #CMD        
#+END_SRC
** Docker File

#+BEGIN_SRC sh
# To delete used image 
docker system prune -a # remove  unused images,container
docker pull msql:5

# -e : password
docker run -itd --name sathish_mydb -e mYSQL_ROOT_PASSWORD=DEVOPS@12345 
# Interview : How to pass password(mysql) in docker cli

dokcer exec -it 015ffdcb /bin/bash
mysql -u root -p



#+END_SRC
** Run(Execute) Docekr file 
Run a docker file
#+BEGIN_SRC sh
#
#   Build the docker image by docker-file
#
docker build -t docker_file_name  # -t: tag #-f : docker file path
docker build -t sathish -f dockerfile-dev . # . : current dir

#
# start container 
#
docker run -itd sathish

# inside the container

#+END_SRC

#+BEGIN_SRC sh
# docker run -it sathish

java -jar jenkins.war

#+END_SRC
** install jenkins in Docker using (java -jar ) cmd
#+BEGIN_SRC sh
FROM centos:7
LABEL name="sathish-devopstrainer"

RUN yum -y update && \
    yum install java-1.8.0-openjdk -y;

ENV JAVA_HOME /usr/lib/jvm/java-1.8.0-openjdk-1.8.0.242.b08-0.el7_7.x86_64/jre/bin/java
ENV PATH ENV JAVA_HOME /usr/lib/jvm/java-1.8.0-openjdk-1.8.0.242.b08-0.el7_7.x86_64/jre/bin/java/bin:$PATH

RUN export JAVA_HOME
RUN export PATH

WORKDIR /opt
EXPOSE 8081
ADD https://updates.jenkins-ci.org/download/war/2.229/jenkins.war .
RUN java -jar jenkins.war
#ENTRYPOINT ["java", "-jar", "jenkins.war"]
#cat /root/.jenkins/secrets/initalAdminPassword



#
#    Install tomcat  
#

#ADD http://apachemirror.wuchna.com/tomcat/tomcat-9/v9.0.33/bin/apache-tomcat-9.0.33.tar.gz .
#RUN tar -xvf apache-tomcat-9.0.33.tar.gz
#RUN sh /opt/apache-tomcat-9.0.33/bin/startup.sh





#+END_SRC
* [7th April] Docker File [Cmd And Entripoint]
- Difference
 - Examin
 - Override
 - default
- Cmd 
 - 1
   - To execute a msg while running inside container
     -  CmD 'echo hai' or CMD ["ECHO" "Hai"]
     -  Ex: RUN mkdir /opt/satish
     -      CmD 'echo floder created'
 -2 cmd can be OVERRIDE while entrpoint can't be override but appended
 -3 passs ${1} parameter to shell scripts inside docker-file 

 To execute a msg while running inside container
#+BEGIN_SRC sh
docker run -it sathish-own echo directory created
docker run -it sathish-own echo sathish folder is created
#+END_SRC

-2 cmd can be OVERRIDE while entrpoint can't be override but appended

#+BEGIN_SRC sh
# FileName : dockerfile
FROM centos
RUN mkdir /opt/azuredevops
CMD ["echo", "floder created"]
#+END_SRC

#+BEGIN_SRC sh
docker run -it sathish-owm
docker run -it sathish-own  echo directory created
# directory created  # cmd is override 
#+END_SRC

#+BEGIN_SRC sh
# FileName : dockerfile
FROM centos
RUN mkdir /opt/azuredevops
ENTRYPOINT ["echo", "floder created"]
#+END_SRC
 
#+BEGIN_SRC sh
docker run -it sathish-owm
docker run -it sathish-own  echo sathish is created # we see it is not over-ride but appended
# floder created echo sathish is created
#+END_SRC

-3 passs ${1} parameter to shell scripts inside docker-file 
-4 To run default process   
#+BEGIN_SRC sh
# cat deployment.sh
env= $1
echo "$1 is working in IBM"
#+END_SRC

#+BEGIN_SRC sh
FROM centos
WORKDIR /opt
copy deployment.sh .
ENTRYPOINT ["sh","deployment.sh"]
CMD ["sathish"]   # Sathish is paramenter to ENTRYPOINT
#+END_SRC

#+BEGIN_SRC sh
docker build -t sathish-own -f dockerfile_1 .
docker run -it sathish-owm 
# sathish is working in IBM

#+END_SRC

Example 2:
#+BEGIN_SRC sh
#cat dockerfile2
FROM centos:7
LABEL name="sathish-devopstrainer"
ENV JAVA_HOME /usr/lib/jvm/java-1.8.0-openjdk-1.8.0.242.b08-0.e17_7.x86_64/jre/bbin/java
RUN yum -y update &&\
    yum install java-1.8.0-openjdk -y;
RUN export JAVA_HOME
CMD ["java","-version"]
#+END_SRC

#+BEGIN_SRC sh
docker build -t sathish-own -f dockerfile2 .
docker run -it sathish-owm 
#+END_SRC


Example : 
#+BEGIN_SRC sh
#wget jenkins.war_url  #download jenkins.war file
 #cat dockerfile2
FROM centos:7
LABEL name="sathish-devopstrainer"
ENV JAVA_HOME /usr/lib/jvm/java-1.8.0-openjdk-1.8.0.242.b08-0.e17_7.x86_64/jre/bbin/java
RUN yum -y update &&\
    yum install java-1.8.0-openjdk -y;
RUN export JAVA_HOME
COPY jenkins.war

CMD ["java","-version"]
#+END_SRC
*** Combination of Cmd and Entypoint 
**** Example hello and hi :
#+BEGIN_SRC sh
FROM centos
ENTRYPOINT ["echo" ]
CMD [ "hello"]
#+END_SRC

#+BEGIN_SRC sh
docker run -it myown
# hello 
docker run -it myown hi 
# hi
#+END_SRC
 
Values can be override we can use combination of entrypoint(Not Overriden contain command ) and cmd(Overriden contain Value or arguments)
  
**** Example : Real time we can use sleep and wait commond.
https://dev.to/gayanhewa/docker-cmd-vs-entrypoint-240l
#+BEGIN_SRC sh
cat dockerfile
#FROM centos
#CMD ["sleep","10"]

docker build -t myown .
docker build -t myown
docker build -t myown echo 20
docker build -t myown 10
#+END_SRC

#+BEGIN_SRC sh
cat dockerfile
#FROM centos
#RUN top
#ENTRYPOINT ["sleep"]
#CMD ["10"]

docker build -t myown .
docker build -t myown
# 10 seconds sys is sleep
docker build -t myown 20
# 20 seconds sys is sleep


#+END_SRC

-3 Change default process
#+BEGIN_SRC sh
docker ps -a    #by default the command is bash
#          COMMAND
#          /bin/bash
#          /bin/bash
#          /bin/bash
#+END_SRC
 
#+BEGIN_SRC sh
cat dockerfile
#FROM centos
CMD ["/bin/sh"]

docker build -t myown .
docker build -t myown
docker ps -a    #by default the command is bash
#          COMMAND
#          /bin/sh
#          /bin/bash
#          /bin/bash
#+END_SRC
* [8th April] Link N Docker-Compose

** Link
Link  : two or more contianers link or communicate each other


#+BEGIN_SRC sh
# To delete used image 
docker system prune -a # remove  unused images,container
docker pull msql
docker pull wordpress
docker run -itd --name mydb -e MYSQL_ROOT_PASSWORD=DEVOPS@12345 mysql:5.7
dokcer exec -it 015ffdcb /bin/bash
mysql -u root -p
#show database;
#create employ (){.......etc
docker run -itd -itd wordpress  --link mydb:mysql -p 83:80 wordpress
#+END_SRC

** Docker Compose : 
Docker Compose is used for running multiple containers of same-image/ Same-organaisation.


#+BEGIN_SRC sh
# cat docker-compose.yml
version: '3.3'

services:
    db:
        image: mysql:5.7
        restart: always
        environment:
            MYSQL_ROOT_PASSWORD: dev@123

    wordpress:
        depends_on:
            - db
        image: wordpress:latest
        ports:
            - "8000:80"
        restart: always
#+END_SRC

Build the project
#+BEGIN_SRC sh
docker-compose up -d
docker ps
#+END_SRC
* [9th April] Docker Swarm
Docker Swarm : To mainitain multiple containers in cluster
- Advantage is
  1. Create Clusters : 
  2. High Avaliablity: Even if one server is not working 
  3. load balancing
  4. Port Forwording

Cluter maintain in form of services (containers or services)
 

Steps for Creating Swarm

- Change Hostname when on aws 
  - hostname swarmmaster
  - hostname swarmwork1
  - hostname swarmworker2
  
- Create a swarm
 - Join container to swarm
  - Go to worker and run join command which is copied in master node
     - docker swarm join
  
#+BEGIN_SRC sh
#to go master server
# How to create a clustser 
docker swarm init --advertise-addr 18.220.116.100 
#it gives the folloing join --token
#example:
docker swarm join --token SWMTKN-1-51n0oal47mvwoyh8l3d2bn8naogqp8xs62wyvh2x6od6f89e8p-efi7qazxaie80f2mepov21d34 18.220.116.100:2377

# step2: go to workers and run join command which is copied in master node
# join nodes: 
docker swarm join --token SWMTKN-1-51n0oal47mvwoyh8l3d2bn8naogqp8xs62wyvh2x6od6f89e8p-efi7qazxaie80f2mepov21d34 18.220.116.100:2377

# step3: node list added in the cluster :
docker node ls 

# step4: if you remove node from cluster
docker swarm leave # Inside the node docker


#+END_SRC
Create a cluster
#+BEGIN_SRC sh
# containers or service :docker run -it --name jenkins jenkins 

# step5: create service (container running) : if you want to bring up 5 service at a time 
docker service create --replicas 5 -p 80:80 --name web nginx
# or 
docker service create -p 83:80 --name nginx-dev nginx

#step6: if you wonna check service is running or not 
docker service ls


# step7: where this is running
docker service ps nginx

#
#To Drain or Stop a server(container) : 
#

# docker node update --avalibility drain <hostaname>
docker node update --avalibility drain worker1
docker 

#
# To activae a server(container):
#

# docker node update --avalibility active hostaname
 
# To show which node is drain/active 
docker node ls 

# see in which node the container(service) is running
docker service ps nginx



# step8: scale up
#docker service scale <servicename>=20
docker service scale nginx=20

# To know how may scale in server we using 
docker service ls

# To which node how many servers are running 
docker service ps nginx

# step9: scale down
# docker service scale <servicename>=5
docker service scale nginx=5

# step 10: if you wonna remove service
docker service rm servicename


# to leave the swarm cluster
docker leave <hostname>
docker swarm leave

#+END_SRC
Scale Up or Scale Down
#+BEGIN_SRC sh
master drain or active:

#
#To Drain or Stop a server(container) : 
#

# docker node update --avalibility drain <hostaname>

#
# To activae a server(container):
#

# docker node update --avalibility active hostaname
 


docker service create -p 81:80 --net own-net --name name service 








#  1. create cluter - 
docker swarm init  - 
docker swarm - leader
docker swarm join
docker node ls
docker service create
docker service ls
docker service scale dev=10
docker service ps dev
docker service rm dev
docker service scale dev=2
docker swarm leave --force 
docker node update --availability drain hostname
                   




#K8- kubernetes 
#docker swarm : cluster - docker containers in a cluster we have to maintain mul cluster







#+END_SRC


manager - 
workers


cluster - group of nodes or group of server 

manager
warker-

docker service commands:
Commands:
  create      Create a new service
  inspect     Display detailed information on one or more services
  logs        Fetch the logs of a service or task
  ls          List services
  ps          List the tasks of one or more services
  rm          Remove one or more services
  rollback    Revert changes to a service's configuration
  scale       Scale one or multiple replicated services
  update      Update a service



swarm uses:

create cluster
create service
port forwarding 
load balance
scale up
scale down
drain & active

* [13th April] Network N Stack
** Docker Network
By default we have 3 networks
- DRIVER
 - bridge   # Going out side container
 - host     # internal- connect containers
 - null     #

Sub net : it is a part of network

Class A
Class B
Class C - /16
Class D - /24

EX:
10.1.0.0/24    24=8*3                10.1.0.X  (X:0-251)
10.1.0.0/16    16=8*2                10.1.X.X  (X:0-251) 4 : ARE RESERVERD

 #+BEGIN_SRC sh
# docker network:

docker network create -d bridge --subnet 10.1.0.0/16 --ip-range 10.1.5.0/24 --gateway 10.1.0.1 easter # easter: name of network
# subnet
# gateway



# list:
docker network ls 

remove:
# docker network rm networkname

# remove unused networks
docker network prune 

# see networkinfo or container info:
# docker network inspect <network-name> 
docker network inspect easter
#container:
#docker inspect <containerid>

# example:
docker network create -d bridge --subnet 10.1.0.0/16 --ip-range 10.1.5.0/24 --gateway 10.1.0.1 easter  

docker network ls
docker network inspect devops

docker run -itd --name sathish-dev --net easter --ip 10.1.0.91 centos:7 # set: network: easter  and ip-address of container: ip:10.1.0.91
docker ps
docker exec -it e8a9ef45586c /bin/bash


# own network                               # docker network create -d bridge --subnet 10.1.0.0/16 --ip-range 10.1.5.0/24 --gateway 10.1.0.1 easter  
# we can assigen our ip to container        # docker run -itd --name sathish-dev --net easter --ip 10.1.0.91 centos:7 
# 


# 1. docker network create done
# 2. docker network ls done 
# 3. dpcker network rm  
# 4. docker network prune - delete unused network
# 5. docker network inspect continerid 
#+END_SRC

** Docker Stack 
1. multiple containers
2. scale up
3. Formate : yml

#+BEGIN_SRC sh
#stack:
---
version: '3'
services:

 mydb:
  image: mysql:5
  environment:
    MYSQL_ROOT_PASSWORD: DEV@123

 myword:
   image: wordpress
   ports:
    - 83:80
   deploy:       # main diff btw compose and stack : 
     replicas: 3 # scale
     placement:  # at which place should it run
       constraints:
         - node.hostname == stackslave

     resources:    # hardware resources 
       limits:
         cpus: "0.01"
         memory: 100M

#  # RUN STACK FILE
# docker stack deploy -c name.yml mystack

# To inspect which node the stack is running
docker stack ps mystack
docker stack rm mystack # remove the stack

########################################################################

#Example :stack2:

version: '3'
services:
  myjenkins:
     image: jenkins
     ports:
      - 8083:8080
     deploy:
       replicas: 2
       placement:
         constraints:
          - node.hostname == stackmaster
       resources:
         limits:
           cpus: "0.5"
           memory: 100M



stack3:
---
version: '3'
services:
  myjenkins:
     image: jenkins
     ports:
      - 8083:8080
     deploy:
       replicas: 2
       placement:
         constraints:
          - node.hostname == stackmaster

  mynginx:
    image: nginx
    ports:
      - 83:80
    deploy:
      replicas: 2
      placement:
         constraints:
            - node.hostname == stackslave
			
			stack4:
			
			---
version: '3'
services:
  myjenkins:
     image: jenkins
     ports:
      - 8083:8080
     deploy:
       replicas: 2
       placement:
         constraints:
          - node.hostname == stackmaster

  mynginx:
    image: nginx
    ports:
      - 83:80
    deploy:
      replicas: 2
      placement:
         constraints:
            - node.hostname == stackslave




stack5:
version: '3'
services:
 devserver:
    image: jenkins
    ports:
     - 8082:8080
    deploy:
      replicas: 2
      placement:
        constraints:
          - node.hostname == stackslave

#+END_SRC
* [24th April] Kubernetics
Open source contaner managment and orchestration

Step1 : install docker for kubernetics in both master and slave
https://kubernetes.io/docs/setup/production-environment/container-runtimes/

Step 2 : install kubelet kubeadm kubectl in both master and slave
https://kubernetes.io/docs/setup/production-environment/tools/kubeadm/install-kubeadm/

Installing kubeadm, kubelet and kubectl

- kubeadm: the command to *bootstrap the cluster*.
- kubelet: the component that runs on all of the machines in your cluster and does things like *starting pods and containers*.
- kubectl: the command line util to *talk to your cluster*.

#+BEGIN_SRC sh
sudo apt-get update && sudo apt-get install -y apt-transport-https curl
curl -s https://packages.cloud.google.com/apt/doc/apt-key.gpg | sudo apt-key add -
cat <<EOF | sudo tee /etc/apt/sources.list.d/kubernetes.list
deb https://apt.kubernetes.io/ kubernetes-xenial main
EOF
sudo apt-get update
sudo apt-get install -y kubelet kubeadm kubectl
sudo apt-mark hold kubelet kubeadm kubectl
#+END_SRC




#+BEGIN_SRC sh
#Create a cluster in master
kubeadmin init #<args>

# https://kubernetes.io/docs/setup/production-environment/tools/kubeadm/create-cluster-kubeadm/

# To start using cluster , you need to run the following  as regular user

# # mkdir -p $HOmE/.kube
# # sudo cp -i /etc/kubenetes/admin.conf $HOmE/.kube/config
# # sudo chown $(id -u): $(id -g) $HOmE/.kube/config

# You should now deploy a pod network to the cluster.
# Run "kubectl apply -f [podnetwork].yaml"  with one of  optional  listed at:
   #  ..
# Then you can join any number of worker nodese by running the following on each is root:
#kubeadm join 172.31.85.184:6443 --token jba6u7.rjkwcd9diiw33x7u / --discovery-token-ca-cert-hash sha256:077d9b3794d7e3d1f25222f6a21d505d9c13d1aa36d9cfab9751040eb6ab4ed


kubectl get nodes # To show nodes



# In slave linux
kubeadm join 172.31.85.184:6443 --token jba6u7.rjkwcd9diiw33x7u / --discovery-token-ca-cert-hash sha256:077d9b3794d7e3d1f25222f6a21d505d9c13d1aa36d9cfab9751040eb6ab4ed

# This node has join the cluster

kubectl get nodes

#+END_SRC
* 25th Sonarqube -quality tool 
https://www.swtestacademy.com/sonarqube-tutorial/ 
- Duplicate
- Code Covarage
- Bugs

What is Code Quality ?
Code quality is a indiactor about how quickly developers can add  business to software system.

Alterative gerrit, github,gitlab...etc

- Sonarqube:port-9000

** How to check quality Rules(Bugs, Vulnerabilities,Code Smell)
Bugs            : 
Vulnerabilities : 
Code Smells     : 
Coverage        :
Duplicates      :

https://224926-685269-raikfcquaxqncofqfm.stackpathdns.com/wp-content/uploads/2015/10/sonar_CI_2016-01-26_21-33-42.png

Sonarqube CI (Stages or CI )
 - Developers (Write Code and push on SCm(git,svm, ))
 - Automatic Build(Jenkins, Bamboo or TeamCity) + Code Analysis
 - Code (Analysis)
   - Publish Analysis Report to SQ
 - SQ Supports languages: Java, C/C++, Objective-C, C#, PHP, Flex, Groovy, JavaScript, Python, PL/SQL, COBOL, etc. (note that some of them are commercial)
    - manage Issues : Report to Developers
    - Sonar Qube Database 
         - Oracle
         - mysql
Supports languages: Java, C/C++, Objective-C, C#, PHP, Flex, Groovy, JavaScript, Python, PL/SQL, COBOL, etc. (note that some of them are commercial) 
** Install

- Prerequirement 
  - SonarQube to show GUI
  - Sonar scanner , sonar runner
  - JDK


#+BEGIN_SRC sh
# configure sonar scanner
cd sonar-scanner/conf
cat sonar-scanner.properties
#sonar.host.url=http://localhost:9090

sonar.login=data
sonar.password=admin
sonar.projectKey=devoproject
#sonar.projectName= carona
sonar.projectVersion=1.0
sonar.source=D:/spark/sparkjava-war-example/src/main/java



#+END_SRC
** How to Intgerate sonar with mvn
- Step1: Go to maven mvn installed
- Step2: Open setting.xml under conf
- Step3: Sonar plugin group and sonar profile and added in setting.xml file
- Step4: run following cmd
          mvn package sonar:sonar

#+BEGIN_SRC xml
<plugin>
.......
</plugin>
<profile> 
........
</profile>


#+END_SRC

#+BEGIN_SRC sh
mvn package sonar:sonar
#+END_SRC
** TODO How to Intgrate  sonar with Jenkins
** What is work of a devops
- Setup sonar
- install sonar and sonar scanner 
- Soar scanner and env variable also configured
- 
** Q and Ans

Q)Do you know sonar  ? 
It is a quality

Q) What you do in sonar ?
Setup sonarq
sonar-scanner: 
    sonar.conf: to to add user.., 
* 26th maven Q-Ans session
- how to ignore test cases
  - mvn install -DskipTests
- how to create multi module project
- how to use profile
- what is snapshot and version
- diff ant and mvn
** ignore Test case
#+BEGIN_SRC sh
mvn archetype:generate  -DgroupId=apr -DartifactId=sunday -DarchetypeArtifactId=maven-archetype-webapp -DinteractiveMode=false
tree -L 1
#|- sunday/
#|     |-  src/
#|     |-  pom.xml
cd sunday
mvn install # by default test is running
mvn clean install -DskipTests
#+END_SRC
** how to create multi module project
parent pom : super pom
 - child pom : 

Q) how to create multi module project 
parent pom - superpom
       child pom


parent pom.xml file
india sbi
├── deposit/pom.xml  # child pom file
├── credit/pom.xml   # child pom file
├── loan/pom.xml     # child pom file
└── pom.xml          #  parent pom file
#+BEGIN_SRC sh
mvn archetype:generate  -DgroupId=india -DartifactId=sbi -DarchetypeArtifactId=maven-archetype-webapp -DinteractiveMode=false

rm src 

mvn archetype:generate  -DgroupId=india -DartifactId=deposit -DarchetypeArtifactId=maven-archetype-webapp -DinteractiveMode=false


mvn archetype:generate  -DgroupId=india -DartifactId=credit -DarchetypeArtifactId=maven-archetype-webapp -DinteractiveMode=false

mvn archetype:generate  -DgroupId=india -DartifactId=loan -DarchetypeArtifactId=maven-archetype-webapp -DinteractiveMode=false

#+END_SRC

#+BEGIN_SRC xml
<-- cat pom.xml  --># remove build and plugins 
<packaging>pom</packaging>  

<modules>
<module>deposit</module>
<module>credit</module>
<module>loan</module>
 </modules>

mvn package
#+END_SRC

** profiles
Q)why do we use profile ?
A) - to set of configuration file
   - Using profile
      - you can customize build for diff enviroment.
https://books.sonatype.com/mvnref-book/reference/profiles-sect-maven-profiles.html

sunprofile
├──dev/application.property 
├──sit/application.property
├──pre production/application.property
└──production/application.property

tomcat  - is consist of war file 
jboss   - is consist of ear file
weblogics - is cluster ( :dev1 dev2 dev3)

profile consist of # jar micro-servies
*** create a profile  
#+BEGIN_SRC sh
mvn archetype:generate  -DgroupId=aprprofile -DartifactId=sunprofile -DarchetypeArtifactId=maven-archetype-webapp -DinteractiveMode=false

#├── pom.xml
#└── src
#    ├── main
#    │    └── java
#    │         └── app.java
#    └── test
cd src/main/
mkdir profiles
cd profiles/
mkdir dev sit preprod prod
echo -e  "env=dev\nurl=https:10.9.68.7:8080/dev\nusername=dev\npasswd=dev@123" > dev/application.property
echo -e  "env=sit\n\nurl=https:10.9.68.7:8080/dev\username=sit\npasswd=sit@123" > sit/application.property
echo -e  "env=preprod\n\nurl=https:10.9.68.7:8080/dev\username=preprod\npasswd=preprod@123" > preprod/application.property
echo -e  "env=prod\nurl=https:10.9.68.7:8080/\ndev\username=prod\npasswd=prod@123" > prod/application.property
#├── pom.xml
#└── src
#    ├── main
#    │   ├── java
#    │   │   └── app.java
#    │   └── profile
#    │       ├── dev
#    │       │   └── application.property
#    │       ├── preprod
#    │       │   └── application.property
#    │       ├── prod
#    │       │   └── application.property
#    │       └── sit
#    │           └── application.property
#    └── test

# add profile dev,sit,preprod,prod in pom.xml

#+END_SRC
*** edit pom.xml file
#+BEGIN_SRC xml
<profiles>
    <profile>
        <id>dev</id> 
        <properties>  
               <build.profile.id>dev</build.profile.id> 
        </properties>  
               <build>
                   <resources>
                       <resource> 
                           <directory>src/main/profiles/dev</directory>
                       </resource> 
                   </resources>
               </build>
        <id>sit</id> 
        <properties>  
               <build.profile.id>sit</build.profile.id> 
        </properties>  
               <build>
                   <resources>
                       <resource> 
                           <directory>src/main/profiles/sit</directory>
                       </resource> 
                   </resources>
               </build>
        <id>preprod</id> 
        <properties>  
               <build.profile.id>preprod</build.profile.id> 
        </properties>  
               <build>
                   <resources>
                       <resource> 
                           <directory>src/main/profiles/preprod</directory>
                       </resource> 
                   </resources>
               </build>
        <id>prod</id> 
        <properties>  
               <build.profile.id>prod</build.profile.id> 
        </properties>  
               <build>
                   <resources>
                       <resource> 
                           <directory>src/main/profiles/prod</directory>
                       </resource> 
                   </resources>
               </build>
   </profile>
</profiles>

#+END_SRC

*** pacakge with profile
#+BEGIN_SRC sh
mvn package -Pdev
mvn package -Psit
mvn package -Ppreprod
mvn package -Pprod
# to see the package 
cd sunprofile
cd target
ls 
# sunprofile-1.0-SNAPSHOT.jar     JAR-File 

# we deploy the .jar files to tomcat server

if [-f credi.jar]then;
service credit start
service credit status
service credit stop
service credit restart

if [all]
credit.jar
deposit.jar

#+END_SRC
* Sonar 
** Install sonarqube
*** create the sonarqube user:
#+BEGIN_SRC sh
sudo adduser --system --no-create-home --group --disabled-login sonarqube
sudo apt-get install unzip

sudo wget https://binaries.sonarsource.com/Distribution/sonarqube/sonarqube-7.5.zip
sudo unzip sonarqube-7.5.zip
sudo rm sonarqube-7.5.zip
sudo chown -R sonarqube:sonarqube /opt/sonarqube


#+END_SRC

*** Database setup
#+BEGIN_SRC sh
mysql> CREATE USER sonarqube@'localhost' IDENTIFIED BY 'Dev@1234';
GRANT ALL ON sonarqube.* to sonarqube@'localhost';
FLUSH PRIVILEGES;
EXIT;
#+END_SRC

*** Configure the sonar
#+BEGIN_SRC sh
sudo nano sonarqube-7.5/conf/sonar.properties

# SonarQube wil use to access the database to the username and password you created for MySQL:

#sonar.jdbc.username=sonarqube
#sonar.jdbc.password=Dev@1234

# SonarQube to use MySQL as the database driver:

# # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # #  
# # # Tell SonarQube to use MySQL as the database driver:
# # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # #  
nano /opt/sonarqube/sonarqube-7.5/conf/sonar.properties
#sonar.jdbc.url=jdbc:mysql://localhost:3306/sonarqube?useUnicode=true&characterEncoding=utf8&rewriteBatchedStatements=true&useConfigs=maxPerformance&useSSL=false

# # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # #  
# # # Nginx will handle the communication between the SonarQube clients and your server, so you will tell SonarQube to only listen to the local address.
# # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # #  
nano /opt/sonarqube/sonarqube-7.5/conf/sonar.properties
# sonar.web.javaAdditionalOpts=-server
# sonar.web.host=127.0.0.1

# you will use Systemd to configure SonarQube to run as a service so that it will start automatically upon a reboot.
# sudo nano /etc/systemd/system/sonarqube.service



#
# start sonarqube service 
#
service sonarqube start
service sonarqube status


#+END_SRC

*** install sonar scanner 
#+BEGIN_SRC sh
mkdir /opt/sonarscanner
cd /opt/sonar/scanner

sudo wget https://binaries.sonarsource.com/Distribution/sonar-scanner-cli/sonar-scanner-cli-3.2.0.1227-linux.zip

sudo unzip sonar-scanner-cli-3.2.0.1227-linux.zip
sudo rm sonar-scanner-cli-3.2.0.1227-linux.zip
sudo nano sonar-scanner-3.2.0.1227-linux/conf/sonar-scanner.properties
vi /opt/sonarscanner/sonar-scanner-3.2.0.1277-linux
# sonar.host.url=https://sonarqube.example.com
sudo chmod +x sonar-scanner-3.2.0.1277-linux/bin/sonar-scanner

sudo ln -s /opt/sonarscanner/sonar-scanner-3.2.0.1227-linux/bin/sonar-scanner /usr/local/bin/sonar-scanner


#+END_SRC
** Integrate maven with sonar
https://docs.sonarqube.org/latest/analysis/scan/sonarscanner-for-maven/


* Next Topics to covered
** TODO Continuous Deployment
** TODO Phase 5: Continuous Monitoring 
(Tools Used: Splunk, ELK Stack, Nagios, New Relic)
Nagios: is a monitoring tool

- disc space
- services 
- URL avaialbility


www.dev-facbook.com
www.sit-facebook.com
www.preprod-facebook.com
www.prod-facebook.com

master - nagios

slave - linux  NRPE 
window - slave NSclient
** Real Time Sceanior
Real time there are 5 environment
- dev env
- sit env
- uat env 
- pre production
- production

(development, sit (System Integration and Testing),uat (User Acceptance Testing),prod)
Real time : In dev env has 6 servers : shared a and shared b
sit -6
uat -9 servers (performance is also tested)
pre-production (16 -servers)
production (20-servers)

`
